<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="email：summer15y@163.com">
<meta property="og:type" content="website">
<meta property="og:title" content="HotSummer">
<meta property="og:url" content="http://yoursite.com/page/6/index.html">
<meta property="og:site_name" content="HotSummer">
<meta property="og:description" content="email：summer15y@163.com">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HotSummer">
<meta name="twitter:description" content="email：summer15y@163.com">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>





  <title> HotSummer </title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">HotSummer</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/28/ML-MLT-7-adaBoost/" itemprop="url">
                  机器学习技法第八课——Adaptive Boosting
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-28T22:41:16+08:00" content="2016-07-28">
              2016-07-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是本人学习<a href="http://www.csie.ntu.edu.tw/~htlin/" target="_blank" rel="noopener">林轩田老师</a>教授的机器学习技法第八课——Adaptive Boosting——的笔记。</p>
<p>不同于 <a href="/2016/07/23/ML-MLT-6-blendingBagging/" title="Blending and Bagging">Blending and Bagging</a>，Boosting 提供一种增强式集成学习方法，它在顺序训练各模型时，要求后面的模型着重训练前面的模型失误的数据，使得总的模型误差不断减小。Adaptive Boosting，简称 AdaBoost， 是 Boosting 中的一种。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/208_handout.pdf" target="_blank" rel="noopener">课件</a></li>
<li><a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost wikipedia</a></li>
</ul>
<h3 id="AdaBoost-的形象类比与流程概要"><a href="#AdaBoost-的形象类比与流程概要" class="headerlink" title="AdaBoost 的形象类比与流程概要"></a>AdaBoost 的形象类比与流程概要</h3><p>课上举的例子实在太形象了，一定得记下啊。Boosting 好比老师教一群小学生（多个模型）学习如何辨识苹果（集成学习）。这里有一堆图片（数据），其中有的是苹果的，还有不是苹果的。老师让学生 A 讲一条辨识苹果的规则（训练一个模型），然后特别指出他/她出错的图片（强调标识失败数据），让下一个同学提出新的规则（训练下一个模型），如此往复，最终可以得到一系列规则，虽然每条规则的辨识能力可能都很弱，但组合起来可能就是很强了（一系列弱模型集成为强模型）。</p>
<p>那么，AdaBoost 的流程就比较清楚了。模型 $g$ 辨识失败的数据， $g(\mathbf{x_n}) \ne y_n$ ，称为问题数据, 辨识正确的数据，称简单数据。以下是大致流程：</p>
<ol>
<li>依次训练各模型</li>
<li>在一个模型训练完成后，向下一个模型强调问题数据</li>
<li>为每个模型分配权重，集成各模型</li>
</ol>
<h3 id="“强调”问题数据"><a href="#“强调”问题数据" class="headerlink" title="“强调”问题数据"></a>“强调”问题数据</h3><p>明显流程第二点是关键。如何才能做到对模型”强调”问题数据呢？这里的“强调”，可以翻译为增加模型在问题数据上犯错的代价。在<a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习基石</a>，老师提到过一些方法。比如，在训练前，复制问题数据 $n$ 份，如果模型在其中一个数据上犯错，就相当于犯了 $n$ 次错，达到“强调”的目的。这里使用的方法是，如果抽取到问题数据做训练，就对 error function 乘上一个系数 $u$ （大于一）。这样，如果模型在问题数据上犯错，error 会扩大 $u-1$ 倍。以下把这种处理方法称为“为数据分配权重”。</p>
<p>实际上，AdaBoost 不仅为问题数据分配权重，也为简单数据分配权重。不过没差，只要能达到“强调”问题数据的效果就行。这里引入 $m$:</p>
<p>$$m = \sqrt{\frac{1-e}{e}}$$</p>
<p>其中 $e$ 表示模型的失误率。AdaBoost 对问题数据乘以 $m$ ，对简单数据除以 $m$ 。其中有两点值得注意。</p>
<p>第一，如果 $e \lt 0.5$， 则 $m \gt 1$，问题数据确实会被“强调”；而当 $e \gt 0.5$ 时， $m \lt 1$ ，问题数据似乎不被“强调”，反而简单数据被“强调”了。其实不差，当 $e \gt 0.5$ 时，意味着模型辨识能力比瞎猜（ $e=0.5$ ）都不如，在最后模型结合时给它分配负权重，把它的辨识结果反过来，这时就应该向后面的模型“强调”简单数据。</p>
<p>第二，注意 $m(e)\;with\;e \gt 0$ 是一个单调下降的函数。这意味着， $e$ 越小，辨识越准确，模型出错也越少， $m$ 也会越大，AdaBoost “强调问题数据”越是“厉害”。为什么在模型出错更少时“更强调”问题数据呢？这是为了平衡简单数据与问题数据的影响，进而训练出更不同（diverse）的模型（对集成学习来说，模型 diversity 越高，效果越好）。（?-?对这话的因果关系存疑）实际上， $m$ 是推导的结果（参见 <a href="https://en.wikipedia.org/wiki/AdaBoost" target="_blank" rel="noopener">AdaBoost</a>），在推导过程中似乎并未对此解释或假设，但以上论点也是比较合理的假说。</p>
<h3 id="模型权重公式"><a href="#模型权重公式" class="headerlink" title="模型权重公式"></a>模型权重公式</h3><p>$$ \alpha = \ln m = \ln \sqrt{\frac{1-e}{e}}$$</p>
<p>当 $e \gt 0.5$ 时， $\alpha \lt 0$。 所以在预测能力小于0.5时，模型被分配负权重，反之，权重为正。</p>
<h3 id="AdaBoost-流程"><a href="#AdaBoost-流程" class="headerlink" title="AdaBoost 流程"></a>AdaBoost 流程</h3><ul>
<li>$\mathbf{u}=[\frac{1}{N},\frac{1}{N},\frac{1}{N},…]$，长度为 $N$ ，记录每个数据的权重</li>
<li><p>for t=1,2,…,T</p>
<ul>
<li>根据训练数据与 $\mathbf{u}$ 训练出模型 $g_t$</li>
<li>计算</li>
</ul>
<p>$$m = \sqrt{\frac{1-e}{e}}\quad with\; e=\frac{\sum u_n[y_n \ne g_t(\mathbf{x_n})]}{\sum u_n}$$</p>
<ul>
<li><p>更新 $\mathbf{u}$</p>
<p>$$u_n = \left{ \begin{array}{l}<br>u_n \cdot m,\quad y_n \ne g_t(\mathbf{x_n})\<br>u_n / m,\quad y_n = g_t(\mathbf{x_n})<br>\end{array} \right.$$</p>
</li>
<li><p>计算 $\alpha_t = \ln (m)$</p>
</li>
</ul>
</li>
<li>返回模型 $G(\mathbf{x})=sign (\sum \alpha_t g_t(\mathbf{x}))$</li>
</ul>
<h3 id="AdaBoost-的理论保证"><a href="#AdaBoost-的理论保证" class="headerlink" title="AdaBoost 的理论保证"></a>AdaBoost 的理论保证</h3><p>VC Bound：</p>
<p>$$E<em>{out}(G)\le E</em>{in}(G) + O\left( \sqrt{O(d_{vc}(H) \cdot T\log T) \cdot \frac {\log N}{N}}  \right)$$</p>
<p>$T$ 表示迭代的次数，实践证明，当迭代达到 $T=\log N$ 时， $E<em>{in}$ 会比较小，而此时的 VC Bound 也不太大，所以 $E</em>{out}$ 可以做得比较小。</p>
<h3 id="基础模型选择——决策树桩"><a href="#基础模型选择——决策树桩" class="headerlink" title="基础模型选择——决策树桩"></a>基础模型选择——决策树桩</h3><p>流行选择 <a href="/2016/08/03/ML-MLT-8-decisionTree/" title="决策树桩（decision stump）">决策树桩（decision stump）</a> 作为基础模型（base algorithm）。决策树桩是深度为一的决策树，典型的弱分类器，常被用作集成学习中的基础模型。它的分类器为：</p>
<p>$$h_{s,i,\theta}(\mathbf{x}) = s \cdot sign(x_i - \theta)$$</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/23/ML-MLT-6-blendingBagging/" itemprop="url">
                  机器学习技法第七课——Blending and Bagging
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-23T11:03:24+08:00" content="2016-07-23">
              2016-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是本人学习林轩田老师的机器学习技法第七课——Blending and Bagging。第七至第十一课学习 ML 中的各种集成学习（<a href="https://en.wikipedia.org/wiki/Ensemble_learning" target="_blank" rel="noopener">Ensemble Learning</a>）算法。简单地讲，Ensemble 集成各种模型为一个最终模型。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/207_handout.pdf" target="_blank" rel="noopener">课件</a></li>
<li><a href="http://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">Kaggle Ensembling Guide</a></li>
<li><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">Understanding the Bias-Variance Tradeoff</a></li>
<li><a href="/2016/08/12/ML-validation/" title="模型验证">模型验证</a></li>
<li><a href="/2016/08/14/Math-PrStats-bootstrapping/" title="Bootstrapping">Bootstrapping</a>
</li>
</ul>
<h3 id="误差的-bias-和-variance"><a href="#误差的-bias-和-variance" class="headerlink" title="误差的 bias 和 variance"></a>误差的 bias 和 variance</h3><p>在此文——<a href="http://scott.fortmann-roe.com/docs/BiasVariance.html" target="_blank" rel="noopener">Understanding the Bias-Variance Tradeoff</a>——中有介绍，同种模型训练由于参数、抽样等不同，得到的模型的误差会有一定的随机性，所以有了模型误差的 bias 与 variance 的概念。</p>
<p>简单地讲，bias 指误差的期望，即模型的预测偏离正确值的期望。而 variance 即误差的方差，衡量模型误差的分散程度。这两个值当然是越小越好。</p>
<h3 id="Blending"><a href="#Blending" class="headerlink" title="Blending"></a>Blending</h3><p>Blending 是十分自然的集成方法。简单地讲，就是将各模型的预测作为数据进行回归或分类训练将其结合。训练过程如下：</p>
<ol>
<li>将训练集 $D<em>{train}$ 分为 $D</em>{train}^-$ 和 $D_{val}$，每条数据可表示为 $(x_1, x_2,…,y)$</li>
<li>在 $D_{train}^-$ 上，训练出各模型 $G^-=(g_1^-(\mathbf{x}), g_2^-(\mathbf{x}), g_3^-(\mathbf{x}),…)$</li>
<li>在 $D<em>{val}$，各模型分别做出预测，组合成新的数据集 $D</em>{pred}$，每条数据可表示为 $\Phi(\mathbf{x}) = (g_1(\mathbf{x}),g_2(\mathbf{x}),g_3(\mathbf{x}),…,y)$</li>
<li>在 $D_{train}$ 上，训练出各模型 $G=(g_1(\mathbf{x}), g_2(\mathbf{x}), g_3(\mathbf{x}),…)$</li>
<li>在 $D_{pred}$ 上，进行分类或回归训练，得到 Blending 模型参数，结合 $G$ 得到最终模型</li>
</ol>
<p>(注：$x_i$ 表示数值，加粗 $\mathbf{x}$ 表示一个向量，$\mathbf{x}=(x_1, x_2,…,x_n)$) 进行测试时，先用 $G$ 做出预测作为输入代入 Blending 模型得到最终预测值。这里有2个问题。</p>
<p>为什么要把 $D<em>{train}$ 分为 $D</em>{train}^-$ 和 $D_{val}$，而不直接在训练集上做训练同时做预测，然后作为 Blending 的训练数据？因为训练得到的模型已经“知道了”其训练数据，在其训练数据上做预测不能反映其预测能力的真实情况，会付出复杂度方面的代价。所以，跟模型选择中所做的验证一样，需要使用模型未知的数据做验证。</p>
<p>为什么使用 $G$ 而非 $G^-$ 得到最终模型？$G$ 在 $D<em>{train}$ 上训练得到，比在更小的训练集 $D</em>{train}^-$ 得到的 $G^-$ 更优。</p>
<p>在课上，老师证明了各模型 $E<em>{out}$ 的期望大于 Blending 模型 $E</em>{out}$ 的期望，也就是说，Blending 模型的预测优于各模型的“平均水平”。（实际上只证明了 uniform blending，在此不细究）</p>
<h4 id="Stacking"><a href="#Stacking" class="headerlink" title="Stacking"></a>Stacking</h4><p>根据博文 <a href="http://mlwave.com/kaggle-ensembling-guide/" target="_blank" rel="noopener">Kaggle Ensembling Guide</a>，Blending 可视为 Stacking 的简化。（Stacking 远早于 Blending 被提出）现在很多研究者视两者等同。</p>
<p>可以很容易发现，Blending 的一至三步与 <a href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89#Holdout_.E9.A9.97.E8.AD.89" target="_blank" rel="noopener">Hold-out Validation</a> 的步骤是相同的。存在多个模型时，常使用验证来选择模型，而 Hold-out 就是其中最基本的一种。而 Stacking 使用 <a href="https://zh.wikipedia.org/wiki/%E4%BA%A4%E5%8F%89%E9%A9%97%E8%AD%89#Holdout_.E9.A9.97.E8.AD.89" target="_blank" rel="noopener">Cross-Validation</a>。</p>
<p>在 <a href="/2016/08/12/ML-validation/" title="模型验证">模型验证</a> 中， Cross-Validation 虽然比使用 Hold-out Validation 复杂，但是 Stacking 得到的 $D<em>{pred}$ 与 $D</em>{train}$ 数据量相等，而 Blending 得到的 $D<em>{pred}$ 与 $D</em>{val}$ （一般取 $D_{train}$ 的10%）等量，较小。</p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>又称 Bootstrap Aggregation, 基于统计学上的 <strong><a href="/2016/08/14/Math-PrStats-bootstrapping/" title="Bootstrapping">Bootstrapping</a></strong> 方法。简单地讲，就是从一个样本集中有放回地抽样得到多个样本集。</p>
<p>Bagging 利用 Bootstrapping 的原理，在训练集 $D_{train}$ 上有放回地抽样得到多个训练集 $D_1^-$, $D_2^-$, $D_3^-$,…，然后用抽取的训练集训练模型，由于抽取得到的训练集各不相同，得到的模型也各不相同（除非训练不受训练集影响，那还训练干嘛）。在预测时，取所有模型预测的均值。</p>
<p>Bagging 能够降低模型预测的 varaince 误差，特别适用于对样本敏感的波动比较大的模型。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/10/ML-MLT-5-supportVectorRegression/" itemprop="url">
                  机器学习技法第六课——Support Vector Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-10T16:44:46+08:00" content="2016-07-10">
              2016-07-10
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是本人学习林轩田老师的机器学习技法第六课——Support Vector Regression——的课堂笔记。</p>
<p>这节课介绍两个模型，与之前的 SVM 不同，都采用二次误差，一个是”kernel ridge regression”，另一个比较重要，是”Support Vector Regression”。最后，针对“机器学习基石”及本课程所讲的分类方法做一个总结。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/206_handout.pdf" target="_blank" rel="noopener">课件</a></li>
<li><a href="/2016/06/26/ML-MLT-4-kernelLogisticRegression/" title="Kernel Logistic Regression">Kernel Logistic Regression</a></li>
<li><a href="http://blog.csdn.net/google19890102/article/details/27228279" target="_blank" rel="noopener">岭回归</a></li>
<li><a href="/2016/06/09/ML-MLT-3-softSVM/" title="Soft Margin SVM">Soft Margin SVM</a>
</li>
</ul>
<h3 id="Kernel-Ridge-Regression"><a href="#Kernel-Ridge-Regression" class="headerlink" title="Kernel Ridge Regression"></a>Kernel Ridge Regression</h3><p>ridge regression，即<a href="http://blog.csdn.net/google19890102/article/details/27228279" target="_blank" rel="noopener">岭回归</a>，简单地讲，是“在平方误差的基础上增加 L2 正则项的回归”。以下是基本公式，这部分目标是将其 kernel 化。<br>$$  \min<em>{\mathbf{w}} \frac{\lambda}{N}\mathbf{w^Tw} + \frac{1}{N} \sum</em>{n=1}^{N}{ (y_n - w^T z_n)^2 }<br>$$</p>
<p>在上节课”“中的“Kernel Logistic Regression”一节，已经讲过“带 L2 正则化的线性模型”可以被 kernel 化，而且 $\mathbf{w}$ 可以被 $\mathbf{z}$ 线性表示，即 $\mathbf{w} = \sum \beta_n z_n$。</p>
<p>因为这部分推导与”Kernel Logistic Regression”的推导相似，在此给出结果：<br>$$  \min<em>{\beta} { \frac{\lambda}{N} \sum</em>{n=1}^{N}\sum_{n=1}^{M} \beta_n \beta_m K(\mathbf{x_n, x<em>m})<br> +\frac{1}{N} \sum</em>{n=1}^{N}{ ( y<em>n - \sum</em>{m=1}^N {\beta_m K(\mathbf{x_m, x_n})} )^2 }}<br>$$</p>
<p>接下来求解。首先矩阵化，代入 $\mathbf{\beta, y}$ 列矩阵，$\mathbf{K<em>{n \times n}}$ 矩阵，$\mathbf{K</em>{m,n}} = K(\mathbf(x_m, x<em>n)$：<br>$$  \min</em>{\beta} {\frac{\lambda}{N} \mathbf{\beta^T K \beta} + \frac{1}{N} ( \beta^T K \beta K - 2 \beta^T K^Ty + y^T y )}<br>$$</p>
<p>求导，梯度为：<br>$$ \nabla = \frac{2}{N} \mathbf{K^T}( (\lambda \mathbf{I} + \mathbf{K}) \mathbf{\beta} - \mathbf{y} )<br>$$</p>
<p>令梯度为 0, 则解得：<br>$$  \mathbf{\beta} = (\lambda \mathbf{I} + \mathbf{K})^{-1} \mathbf{y}<br>$$</p>
<p>推导过程中省略了许多步骤 :-P。需要注意的是，该求解方法时间复杂度为 $O(N^3)$，而且 $\beta$ 内元素值多不为 0。课中讲到，用于分类的”Kernel Ridge Regression”被称作“least squares SVM (LSSVM)”。因为 $\beta_n$ 多数非 0，它求解得到的”Support Vector”非常多。</p>
<h3 id="Support-Vector-Regression"><a href="#Support-Vector-Regression" class="headerlink" title="Support Vector Regression"></a>Support Vector Regression</h3><p>“Support Vector Regression (SVR)”尝试避免”Kernel Ridge Regression”的“Support Vector” dense 问题，同时保留类似二次误差(least squares error)的形式。</p>
<p>相对于 SVM 的 <strong>hinge regression</strong>，Support Vector Regression 采用 <strong>tube regression</strong>（在上节课”“介绍过）。令 $s=w^T z + b$，两者加上 <strong>squared error</strong> 的 error function 表达式为：</p>
<table>
<thead>
<tr>
<th style="text-align:center">err type</th>
<th style="text-align:center">function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">squared err</td>
<td style="text-align:center">$(s-y)^2$</td>
</tr>
<tr>
<td style="text-align:center">tube err</td>
<td style="text-align:center">$\max(abs(s - y) - \epsilon,\; 0)$</td>
</tr>
<tr>
<td style="text-align:center">hinge err</td>
<td style="text-align:center">$\max(1-ys,\; 0)$</td>
</tr>
</tbody>
</table>
<p>（abs 取绝对值函数）很明显，squared err 与 tube err 的变化趋势相近，当 $s \rightarrow +\infty$，$err \rightarrow +\infty$，当 $s \rightarrow -\infty$，$err \rightarrow +\infty$。如果作图，两者都呈一个山谷状。</p>
<p>在 <a href="/2016/06/09/ML-MLT-3-softSVM/" title="Soft Margin SVM">Soft Margin SVM</a> 中，使用了 hinge error，在此将其替换成 tube error 重新推导。<br>$$  \min<em>{b, \mathbf{w}} \frac{1}{2}\mathbf{w^Tw} + C \sum</em>{n=1}^{N}{\max(0, |w^T z_n + b - y_n| - \epsilon)}<br>$$</p>
<p>首先，引入松弛变量 $\xi_n^\bigwedge, \xi<em>n^\bigvee$，同时去掉绝对值：<br>$$  \min</em>{b,\mathbf{w},\xi_n^\bigwedge, \xi_n^\bigvee} \frac{1}{2}\mathbf{w^Tw} + C \sum{ (\xi_n^\bigwedge + \xi_n^\bigvee) } \\<br>s.t.\quad  -\epsilon - \xi_n^\bigvee \le y_n - w^T z_n - b \le \epsilon + \xi_n^\bigwedge \\<br>\xi_n^\bigwedge \ge 0,\quad \xi_n^\bigvee \ge 0<br>$$</p>
<p>之后，引入拉格朗日乘数 $\alpha_n^\bigwedge, \alpha<em>n^\bigvee$，分别对应限制条件的上限与下限，又经过一系列求导、KKT 条件、化简等处理（参考“<a href="/2016/06/09/ML-MLT-3-softSVM/" title="Soft Margin SVM">Soft Margin SVM</a>” :-P），得到最终公式：<br>$$  \min  \frac{1}{2} \sum</em>{n=1}^{n}\sum_{m=1}^{n} (\alpha_n^\bigwedge - \alpha_n^\bigvee)(\alpha_m^\bigwedge - \alpha_m^\bigvee)K(x_n, x<em>m) + \sum</em>{n=1}^N( (\epsilon - y_n) \alpha_n^\bigwedge + (\epsilon ＋ y_n) \alpha_n^\bigvee) \\<br>s.t.\quad \sum(\alpha_n^\bigwedge - \alpha_n^\bigvee) = 0 \\<br>0 \le \alpha_n^\bigwedge \le C, 0 \le \alpha_n^\bigvee \le C<br>$$<br>同样是 QP 问题，求解得出<br>$$  \mathbf{w} = \sum(\alpha_n^\bigwedge - \alpha_n^\bigvee)\mathbf{z_n}<br>$$<br>Support Vector 为 $\alpha_n^\bigwedge - \alpha_n^\bigvee \ne 0$ 对应的数据点，SVR 保证了 SV 的稀疏性。</p>
<h3 id="分类器小结"><a href="#分类器小结" class="headerlink" title="分类器小结"></a>分类器小结</h3><p>目前学习的（二）分类器，可以“线性的”与“kernel化的”，从 error function 看，可分为 “0/1 error”, “hinge error”, “squared/tube error”, “logistic error”。</p>
<table>
<thead>
<tr>
<th style="text-align:center">linear / kernel</th>
<th style="text-align:center">0/1 or hinge error</th>
<th style="text-align:center">squared/tube error</th>
<th style="text-align:center">　logistic error</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">linear</td>
<td style="text-align:center">PLA/pocket</td>
<td style="text-align:center">linear SVR</td>
</tr>
<tr>
<td style="text-align:center">linear</td>
<td style="text-align:center">linear soft-margin SVM</td>
<td style="text-align:center">linear ridge regression</td>
<td style="text-align:center">regularized logistic regression</td>
</tr>
<tr>
<td style="text-align:center">kernel</td>
<td style="text-align:center"></td>
<td style="text-align:center">kernel ridge regression</td>
<td style="text-align:center">kernel regularized logistic regression</td>
</tr>
<tr>
<td style="text-align:center">kernel</td>
<td style="text-align:center">SVM</td>
<td style="text-align:center">SVR</td>
<td style="text-align:center">probabilistic SVM</td>
</tr>
</tbody>
</table>
<p>其中第二、四行是最常用的，老师推荐了开源库 LIBLINEAR 与 LIBSVM。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/30/Math-Calculus-cheatSheet/" itemprop="url">
                  微积分笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-30T19:08:24+08:00" content="2016-06-30">
              2016-06-30
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Math/" itemprop="url" rel="index">
                    <span itemprop="name">Math</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li>《微积分（第2版）（上册）》，傅英定 谢云荪 主编，高等教育出版社</li>
</ul>
<h3 id="微积分系列笔记"><a href="#微积分系列笔记" class="headerlink" title="微积分系列笔记"></a>微积分系列笔记</h3><ul>
<li><a href="/2016/07/30/Math-Calculus-limit/" title="极限">极限</a></li>
<li><a href="/2016/07/30/Math-Calculus-derivation/" title="导数">导数</a></li>
<li><a href="/2016/07/30/Math-Calculus-indefiniteIntegration/" title="不定积分计算">不定积分计算</a></li>
<li><a href="/2016/07/30/Math-Calculus-derivationApplication/" title="导数应用">导数应用</a></li>
<li><a href="/2016/08/16/Math-Calculus-definiteIntegral/" title="定积分">定积分</a></li>
<li><a href="/2016/08/20/Math-Calculus-definiteIntegralApp/" title="定积分的应用">定积分的应用</a></li>
<li><a href="/2016/08/20/Math-Calculus-ordinaryDifferentialEq/" title="常微分方程">常微分方程</a></li>
<li><a href="/2016/09/13/Math-Calculus-multiIntegral/" title="重积分">重积分</a></li>
<li><a href="/2016/09/26/Math-Calculus-multiDerivat/" title="多元函数最值">多元函数最值</a>
</li>
</ul>
<h3 id="常见处理"><a href="#常见处理" class="headerlink" title="常见处理"></a>常见处理</h3><h4 id="对-e-x-2-的积分"><a href="#对-e-x-2-的积分" class="headerlink" title="对 $e^{x^2}$ 的积分"></a>对 $e^{x^2}$ 的积分</h4><p>考虑正态分布</p>
<h4 id="根式常见处理"><a href="#根式常见处理" class="headerlink" title="根式常见处理"></a>根式常见处理</h4><ul>
<li>平方</li>
<li>分子、分母有理化</li>
<li>换元</li>
</ul>
<h4 id="幂指函数处理"><a href="#幂指函数处理" class="headerlink" title="幂指函数处理"></a>幂指函数处理</h4><ul>
<li>指数真底互换</li>
<li>取对数</li>
</ul>
<h4 id="乘法变加法"><a href="#乘法变加法" class="headerlink" title="乘法变加法"></a>乘法变加法</h4><p>取对数</p>
<h4 id="积分被积变量"><a href="#积分被积变量" class="headerlink" title="积分被积变量"></a>积分被积变量</h4><p>非被积变量被视为常数，即使是自变量，如 $f(x) =x \int_a^x f(t) dt$， 也可以自由“出入”积分，如  $f(x) = \int_a^x x f(t) dt$</p>
<h4 id="2-变量不等式证明"><a href="#2-变量不等式证明" class="headerlink" title="2 变量不等式证明"></a>2 变量不等式证明</h4><p>固定一个，变动另一个，即其中一个作为常数，另一个作为变量。另外，区间端点如 $a, b$， 也可视为 2 个变量。</p>
<h4 id="无穷项数列和的极限"><a href="#无穷项数列和的极限" class="headerlink" title="无穷项数列和的极限"></a>无穷项数列和的极限</h4><ul>
<li>夹逼准则</li>
<li>定积分定义</li>
<li>构造函数项无穷级数</li>
</ul>
<h4 id="不定积分"><a href="#不定积分" class="headerlink" title="不定积分"></a>不定积分</h4><p>不定积分的定积分形式： $\int f(x) dx = \int_0^x f(x) dx + C$</p>
<h4 id="max-与-min-函数不等式"><a href="#max-与-min-函数不等式" class="headerlink" title="max 与 min 函数不等式"></a>max 与 min 函数不等式</h4><ol>
<li>$\max(a,b) &lt; c$ 等价于 $a &lt; c\; \&amp;\&amp; \; b &lt; c$</li>
<li>$\min(a,b) &gt; c$ 等价于 $a &gt; c\; \&amp;\&amp; \; b &gt; c$</li>
<li>$\max(a,b) &gt; c$ 的逆命题是 $\max(a,b) \le c$， $\min$ 函数同理</li>
</ol>
<h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><h4 id="对数换底公式"><a href="#对数换底公式" class="headerlink" title="对数换底公式"></a>对数换底公式</h4><p>$$\log_a b = \frac{\log_c b}{\log_c a}=\frac{\ln b}{\ln a}$$</p>
<h4 id="指数真底互换"><a href="#指数真底互换" class="headerlink" title="指数真底互换"></a>指数真底互换</h4><p>$$x^y =a^{y\log_a x}= e^{y\ln{x}}$$</p>
<h4 id="求导公式"><a href="#求导公式" class="headerlink" title="求导公式"></a>求导公式</h4><p> $$(x^a)’ = a x^{a-1}$$</p>
<p> $$(e^x)’ = e^x, \quad (a^x)’ = a^x \ln a$$</p>
<p> $$(\ln x)’ = \frac{1}{x}, \quad (\log_a x)’ = \frac{1}{x \ln a} $$</p>
<p> $$(\sin(x))’ = \cos(x), \quad (\cos(x))’ = -\sin(x)$$</p>
<p> $$(\tan(x))’=\frac{1}{\cos^2 x}, \quad (\cot(x))’ = -\frac{1}{\sin^2(x)}$$</p>
<p> $$(\arcsin(x))’ = \frac{1}{\sqrt{1-x^2}}, \quad (\arccos(x))’ = -\frac{1}{\sqrt{1-x^2}}$$</p>
<p> $$(\arctan (x))’ = \frac{1}{x^2 + 1},\quad (arccot(x))’ = -\frac{1}{x^2 + 1}$$</p>
<p> $$(\sec(x))’ = \sec(x)\tan(x),\quad (\csc(x))’ = -\csc(x)\cot(x)$$</p>
<p> $$\frac{d}{dx}\int_{\psi (x)}^{\varphi (x)}f(t)dt=f\left[\varphi<br>  (x)\right]\varphi ‘(x)-f[\psi (x)]\psi ‘(x)$$</p>
<h4 id="不定积分-1"><a href="#不定积分-1" class="headerlink" title="不定积分"></a>不定积分</h4><p> $$\int \frac{1}{\sqrt{a^2-x^2}} dx = \arcsin \frac{x}{a} + C$$</p>
<p> $$\int \frac{1}{a^2+x^2} dx = \frac{1}{a} \arctan \frac{x}{a} + C$$</p>
<p> $$\int \frac{1}{a^2-x^2} dx = \frac{1}{2a} \ln |\frac{a+x}{a-x}| + C$$</p>
<p> $$\int \sec x dx = \ln |\sec x + \tan x|+ C$$</p>
<p> $$\int \csc x dx = \ln |\csc x - \cot x|+ C$$</p>
<p> $$\int \frac{1}{\sqrt{x^2 \pm a^2}} dx = \ln |x +\sqrt{x^2 \pm a^2}| + C$$</p>
<h4 id="分部积分可循环形式"><a href="#分部积分可循环形式" class="headerlink" title="分部积分可循环形式"></a>分部积分可循环形式</h4><p>$\sqrt{x^2 \pm a^2}, \quad \sqrt{a^2 - x^2}$</p>
<h4 id="几个简单函数的-n-阶导数"><a href="#几个简单函数的-n-阶导数" class="headerlink" title="几个简单函数的 n 阶导数"></a>几个简单函数的 n 阶导数</h4><p> $$(x^\alpha)^{(n)} = \alpha(\alpha-1)…(\alpha-n+1)x^{\alpha-n},\quad (x^n)^{(n)} = n!$$</p>
<p> $$\sin^{(n)}x = \sin(x+\frac{\pi}{2}n), \quad \cos^{(n)}{x} = \cos(x+\frac{\pi}{2}n)$$</p>
<p> $$(\frac{1}{x})^{(n)} = \frac{(-1)^n n!}{x^{n+1}}$$</p>
<p> $$[\alpha u(x) + \beta v(x)]^{(n)} = \alpha u^{(n)}(x) + \beta v^{(n)}(x)$$</p>
<p> $$(uv)^{(n)} = \sum_{k=0}^n u^{(n-k)} v^{(k)}\quad Leibniz 公式$$</p>
<h4 id="三角公式"><a href="#三角公式" class="headerlink" title="三角公式"></a><a href="http://baike.so.com/doc/5350859-5586315.html" target="_blank" rel="noopener">三角公式</a></h4><h5 id="三角与反三角"><a href="#三角与反三角" class="headerlink" title="三角与反三角"></a>三角与反三角</h5><p>$\sec(x)\cos(x)=1,\quad \csc(x)\sin(x)=1,\quad \cot(x)\tan(x)=1,\quad$</p>
<h5 id="两角和"><a href="#两角和" class="headerlink" title="两角和"></a>两角和</h5><p> $$\cos(\alpha+\beta)=\cos \alpha \cdot \cos \beta-\sin \alpha \cdot \sin \beta$$</p>
<p> $$\sin(\alpha + \beta)=\sin \alpha  \cdot \cos \beta + \cos \alpha  \cdot \sin \beta$$</p>
<p> $$\tan(\alpha+\beta)=\frac{\tan\alpha+\tan\beta}{1-\tan\alpha \cdot \tan\beta}$$</p>
<h5 id="倍角公式"><a href="#倍角公式" class="headerlink" title="倍角公式"></a>倍角公式</h5><p> $$\sin(2\alpha)=2\sin\alpha\cdot\cos\alpha$$</p>
<p> $$\cos(2\alpha)=(\cos\alpha)^2-(\sin\alpha)^2=2(\cos\alpha)^2-1=1-2(\sin\alpha)^2$$</p>
<p> $$\tan(2\alpha)=\frac{2\tan\alpha}{1-\tan^2\alpha}$$</p>
<h4 id="等价无穷小"><a href="#等价无穷小" class="headerlink" title="等价无穷小"></a>等价无穷小</h4><p> $$\sqrt[n]{x+1} - 1 \sim \frac{x}{n}$$</p>
<p> $$1-\cos{x} \sim \frac{1}{2} x^2$$</p>
<p> $$\arcsin(x) \sim \sin(x) \sim \tan(x) \sim \arctan(x) \sim x$$</p>
<p> $$\tan(x) - \sin(x) \sim \frac{1}{2}x^3$$</p>
<p> $$ \ln(1+x) \sim x, \quad \log_a(1+x) \sim \frac{x}{\ln a}  $$</p>
<p> $$ e^x - 1 \sim x, \quad a^x - 1 \sim x\ln a $$</p>
<h4 id="不等式"><a href="#不等式" class="headerlink" title="不等式"></a>不等式</h4><ul>
<li>基本不等式：$a + b \ge 2\sqrt{a b}$</li>
<li>$a + b \le 2(a^2 + b^2)$</li>
</ul>
<h4 id="方向余弦"><a href="#方向余弦" class="headerlink" title="方向余弦"></a>方向余弦</h4><p>对 $(\cos \alpha, \cos \beta)$ 有</p>
<p>$$ \cos^2 \alpha + \cos^2 \beta = 1 $$</p>
<h4 id="数列和"><a href="#数列和" class="headerlink" title="数列和"></a>数列和</h4><p>等比数列（几何数列） ${a_n}$ ，$a_n = a_1q^{n-1}$，  和：</p>
<p>$$ S_n = \frac{a<em>1(1-q^n)}{1-q} = \frac{a</em>{n+1} - a_1}{q-1} $$</p>
<h4 id="导数运算"><a href="#导数运算" class="headerlink" title="导数运算"></a>导数运算</h4><p>除法：</p>
<p>$$ (\frac{u}{v})’(x) = \frac{u’(x)v(x) - u(x)v’(x)}{v^2(x)} $$</p>
<p>参数方程： $y=y(t),\; x= x(t)$</p>
<p>$$ \frac{dy}{dx} = \frac{dy}{dt}\frac{dt}{dx} = \cfrac{\frac{dy}{dt}}{\frac{dx}{dt}} $$</p>
<p><strong>复合函数求导的链式法则</strong>： $z=z(u(x,y), v(x,y))$</p>
<p>$$ \frac{\partial z}{\partial x} = \frac{\partial z}{\partial u}\frac{\partial u}{\partial x} + \frac{\partial z}{\partial v}\frac{\partial v}{\partial x} $$</p>
<p>隐函数：若 $F(x,y)=0$ 隐函数存在，则</p>
<p>$$ \frac{dy}{dx} = -\frac{F_x}{F_y} $$</p>
<p>隐函数推广到二元 $F(x,y,z)=0$ 有</p>
<p>$$ \frac{\partial z}{\partial x}=-\frac{F_x}{F_z} $$</p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><h4 id="数列极限"><a href="#数列极限" class="headerlink" title="数列极限"></a>数列极限</h4><p>$\forall \epsilon \gt 0$，$\exists N \gt 0$，当 $n \gt N$ 时，有 $|a<em>n - A| \lt \epsilon$，则 $\lim</em>{n \rightarrow \infty}{a_n} = A$</p>
<h4 id="函数极限（有限值）"><a href="#函数极限（有限值）" class="headerlink" title="函数极限（有限值）"></a>函数极限（有限值）</h4><p><strong>要求</strong> 在 $x_0$ 的某去心邻域有定义，对 $\forall \epsilon \gt 0$，都 $\exists \delta &gt; 0$，使满足 $0 \lt |x-x<em>0| \lt \delta$ 的所有x，都有 $|f(x) - A| \lt \delta$，则 $\lim</em>{n \rightarrow x_0}{f(x)} = A$</p>
<h4 id="二重函数极限"><a href="#二重函数极限" class="headerlink" title="二重函数极限"></a>二重函数极限</h4><p>$f(x,y)$ 的定义为 $D$， $P_0(x_0,y_0)$ 为 $D_f$ 的聚点，对 $\forall \epsilon \gt 0$，都 $\exists \delta &gt; 0$， 使满足 $0&lt;||PP_0||=\sqrt{(x-x_0)^2+(y-y_0)^2}&lt;\sigma$ 的所有 $P(x,y)$， 都有 $|f(x,y)-A|&lt;\sigma$， 则</p>
<p>$$ \lim_{(x,y)\rightarrow (x_0,y_0)} f(x,y) = A$$</p>
<p>二重极限存在则 $P(x,y)$ 以 <strong>任意方式</strong> 接近 $P_0(x_0,y_0)$， 其极限都存在。可以推广到更多元函数极限。</p>
<h4 id="连续"><a href="#连续" class="headerlink" title="连续"></a>连续</h4><p>极限等于函数值，则该处连续。</p>
<h4 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h4><p>$$ f’(x<em>0) = \lim</em>{\Delta x \rightarrow 0} \frac {f(x_0 + \Delta x) - f(x_0)} {\Delta x} $$</p>
<h4 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h4><p>$$ z<em>x= \frac{\partial z}{\partial x} = \lim</em>{\Delta x \rightarrow 0} \frac{f(x_0 + \Delta x, y_0) - f(x_0, y_0)}{\Delta x} $$</p>
<h4 id="二阶偏导"><a href="#二阶偏导" class="headerlink" title="二阶偏导"></a>二阶偏导</h4><p>$$ \frac{\partial }{\partial x}(\frac{\partial z}{\partial x})=\frac{\partial^2 z }{\partial x^2} = f<em>{xx}(x,y),\quad \frac{\partial }{\partial y}(\frac{\partial z}{\partial x})=\frac{\partial^2 z }{\partial x \partial y} = f</em>{xy}(x,y) $$</p>
<h4 id="方向导数"><a href="#方向导数" class="headerlink" title="方向导数"></a>方向导数</h4><p>若 $z=f(x,y)$ 可微，则存在沿 <a href="https://zh.wikipedia.org/wiki/%E6%96%B9%E5%90%91%E9%A4%98%E5%BC%A6" target="_blank" rel="noopener">方向余弦</a> 为 $(\cos\alpha, \cos\beta)$ 的方向 l 的方向导数</p>
<p>$$ \frac{\partial z}{\partial l} = \frac{\partial z}{\partial x} \cos \alpha + \frac{\partial z}{\partial l} \cos \beta $$</p>
<p>方向导数是函数沿 l 方向的变化率。偏导数是沿坐标轴的函数变化率。</p>
<h4 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h4><p>梯度是一个向量：</p>
<p>$$ \mathbf{grad} f= \frac{\partial f}{\partial x} \mathbf{i} + \frac{\partial f}{\partial y} \mathbf{j} $$</p>
<h4 id="全微分"><a href="#全微分" class="headerlink" title="全微分"></a>全微分</h4><p><strong>全增量</strong>：</p>
<p>$$ \Delta z = f(x+\Delta x, y+\Delta y) - f(x,y) $$</p>
<p>若偏导数 $f_x(x_0, y_0）, f_y(x_0, y_0)$ 均存在，且存在极限：</p>
<p>$$ \lim_{\Delta x,\Delta y \rightarrow 0} \frac{\Delta z - (f_x(x_0, y_0） \Delta x + f_y(x_0, y_0） \Delta y)}{\sqrt{\Delta x^2 + \Delta y^2}} = 0 $$</p>
<p>则全微分存在：</p>
<p>$$ dz = f_x(x_0, y_0) dx + f_y(x_0, y_0) dy $$</p>
<p>$f_x(x_0, y_0) dx + f_y(x_0, y_0) dy$ 称为线性主部。可微时有： $\Delta z = f_x(x_0, y_0) \Delta x + f_y(x_0, y_0) \Delta y + o(\sqrt{\Delta x^2+\Delta y^2})$</p>
<h4 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h4><p>若函数在某处可导，则有 $\Delta y = f’(x) \Delta x + o(\Delta x)$， 其中 $dy = f’(x)\Delta x = f’(x) dx$ 即该处微分。$f’(x)\Delta x$ 称为线性主部。</p>
<h4 id="定积分"><a href="#定积分" class="headerlink" title="定积分"></a>定积分</h4><p>关键字：分割，近似，求和，取极限</p>
<p>设函数 $f(x)$ 在有限区间 $[a, b]$ 上有界，将 $[a, b]$ 任意划分为 $n$ 个小区间，分点为：</p>
<p>$$a=x_0&lt;x_1&lt;x_2&lt;…&lt;x_n=b$$</p>
<p>在每个小区间 $[x_{i-1}, x_i]\; (i=1,2,…,n)$ 上任取一点 $\xi<em>i\; (x</em>{i-1} \le \xi_i \le x_i)$， 记</p>
<p>$$ \Delta x_i =x<em>i - x</em>{i-1}\; (i=1,2,…,n),\; \lambda=\max_{1\le i \le n}{\Delta x_i} $$</p>
<p>作和式</p>
<p>$$ \sum_{i=1}^n f(\xi_i)\Delta x_i $$</p>
<p>如果无论区间 $[a,b]$ 怎样划分及点 $\xi_i$ 怎样选取，极限</p>
<p> $$ \lim<em>{\lambda \rightarrow 0} \sum</em>{i=1}^n f(\xi_i)\Delta x_i $$</p>
<p>的值都为同一常数，则称 $f(x)$ 在 $[a,b]$ 上可积，此极限值称为 $f(x)$ 在 $[a,b]$ 上的定积分，记为 $\int_a^b f(x) dx$， 即</p>
<p>$$ \int<em>a^b f(x) dx = \lim</em>{\lambda \rightarrow 0} \sum_{i=1}^n f(\xi_i)\Delta x_i $$</p>
<p>其中 $x$ 称为 <strong>被积分变量</strong>， $f(x)$ 称为 <strong>被积函数</strong> ， $f(x)dx$ 称为 <strong>被积表达式</strong> ， $a,b$ 分别为 <strong>积分下限</strong>， <strong>积分上限</strong>， $\int$ 称为 <strong>积分符号</strong>， 表示和， $[a,b]$ 为 <strong>积分区间</strong> 。</p>
<h4 id="不定积分-2"><a href="#不定积分-2" class="headerlink" title="不定积分"></a>不定积分</h4><p>在定义域内，如果 $(F(x))’ = f(x)$，则<br>$$\int f(x) dx = F(x) + C$$</p>
<h4 id="间断点"><a href="#间断点" class="headerlink" title="间断点"></a>间断点</h4><p>不连续的点。第一类间断点，左右极限都存在。第二类间断点即不属于第一类间断点的间断点。</p>
<h4 id="基本初等函数"><a href="#基本初等函数" class="headerlink" title="基本初等函数"></a>基本初等函数</h4><p>指六类函数：常量函数、幂函数、指数函数、对数函数、三角函数和反三角函数。以上函数通过有限次四则运算或有限次算命运算所得，且能用一个解析式表示的函数，称为 <strong>初等函数</strong>。</p>
<h4 id="驻点"><a href="#驻点" class="headerlink" title="驻点"></a>驻点</h4><p>一阶导数为 0 的 $x$ 值。</p>
<h4 id="极值点"><a href="#极值点" class="headerlink" title="极值点"></a>极值点</h4><p>对 $\forall x \in$ 去心邻域 $(x_0, \delta)$, 都有 $f(x) \lt f(x_0)$ （或 $f(x) \gt f(x_0)$） 则称 $x_0$ 为极大（小）值点。</p>
<h4 id="函数凹凸性"><a href="#函数凹凸性" class="headerlink" title="函数凹凸性"></a>函数凹凸性</h4><p>$f(x)$ 在 $[a,b]$ 连续</p>
<p> $$f(\frac{x_1+x_2}{2}) &lt; \frac{f(x_1) + f(x_2)}{2}$$  </p>
<p> 则下凸，大于则上凸</p>
<h4 id="拐点"><a href="#拐点" class="headerlink" title="拐点"></a>拐点</h4><p>$f(x)$ 在 $x_0$ 附近连续，且两侧凸性相反，则 <strong>$(x_0, f(x_0))$</strong> 为拐点</p>
<h4 id="函数渐近线"><a href="#函数渐近线" class="headerlink" title="函数渐近线"></a>函数渐近线</h4><ul>
<li>垂直渐近线 $x=x_0$</li>
</ul>
<p>$$\lim_{x \rightarrow x_0} f(x) = \infty$$</p>
<ul>
<li>水平渐近线 $y=b$</li>
</ul>
<p>$$\lim_{x \rightarrow \infty} f(x) = b$$</p>
<ul>
<li><p>斜渐近线 $y=k x + b$</p>
<ul>
<li><p>$$\lim_{x \rightarrow \infty} f(x) - (k x + b) = 0$$</p>
</li>
<li><p>$$k =\lim<em>{x\rightarrow \infty} \frac{f(x)}{x},\quad b = \lim</em>{x \rightarrow \infty} f(x) - k x$$</p>
</li>
</ul>
</li>
</ul>
<h4 id="函数曲率"><a href="#函数曲率" class="headerlink" title="函数曲率"></a>函数曲率</h4><p>$\alpha \sim 角度,\quad s \sim 弧长,\quad K \sim 曲率$</p>
<p>$$K = \lim_{\Delta s \rightarrow 0} |\frac{\Delta \alpha}{\Delta s}| = \frac{|y’’|}{(1+y’^2)^{\frac{3}{2}}}$$</p>
<p>圆的曲率： $K = 1 / R$。 <strong>曲率半径：</strong> $1/K$, 曲率圆与函数曲线相切，以曲率半径为半径，曲率中心为曲率圆的圆心。</p>
<h4 id="反常积分"><a href="#反常积分" class="headerlink" title="反常积分"></a>反常积分</h4><p><a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%B8%B8%E7%A9%8D%E5%88%86" target="_blank" rel="noopener">反常积分</a>又叫广义积分，是对普通定积分的推广，指含有无穷上限/下限，或者被积函数含有瑕点的积分，前者称为无穷限广义积分，后者称为瑕积分（又叫无界函数的反常积分）。</p>
<h4 id="无穷级数"><a href="#无穷级数" class="headerlink" title="无穷级数"></a>无穷级数</h4><p>一个无穷序列的元素的和称为无穷级数。序列的通项称作级数的 <strong>通项</strong>， 若为常数，则称作常数项无穷级数，若为函数，称作函数项无穷级数。无穷级数是 <strong>函数逼近理论</strong> 的重要内容之一。</p>
<h3 id="定理"><a href="#定理" class="headerlink" title="定理"></a>定理</h3><h4 id="微分、偏导与连续"><a href="#微分、偏导与连续" class="headerlink" title="微分、偏导与连续"></a>微分、偏导与连续</h4><p>对一阶，可微必可导，可导必连续，连续有极限。</p>
<p>对二阶，可微必偏导和连续，连续有极限。可微的充分条件：偏导函数存在且偏导函数连续。</p>
<h4 id="微分中值定理"><a href="#微分中值定理" class="headerlink" title="微分中值定理"></a>微分中值定理</h4><h5 id="罗尔中值定理（导数根存在定理）"><a href="#罗尔中值定理（导数根存在定理）" class="headerlink" title="罗尔中值定理（导数根存在定理）"></a>罗尔中值定理（导数根存在定理）</h5><p>$f(x)$ 满足三个条件，一、在 $[a,b]$ 连续，二、在 $(a,b)$ 可导，三、 $f(a)=f(b)$ ，则 $\exists \xi \in (a,b)$, 使得 $f’(\xi)=0$。几何意义：存在切线与端点连线平行。</p>
<h5 id="拉格朗日定理"><a href="#拉格朗日定理" class="headerlink" title="拉格朗日定理"></a>拉格朗日定理</h5><p>$f(x)$ 满足二个条件，一、在 $[a,b]$ 连续，二、在 $(a,b)$ 可导，则 $\exists \xi \in (a,b)$, 使得</p>
<p>$$ f’(\xi) = \frac{f(b) - f(a)}{b - a} $$</p>
<p>几何意义：存在切线与端点连线平行。</p>
<h5 id="柯西中值定理"><a href="#柯西中值定理" class="headerlink" title="柯西中值定理"></a>柯西中值定理</h5><p>$f(x),\;g(x)$ 满足二个条件，一、在 $[a,b]$ 连续，二、在 $(a,b)$ 可导，另外， $\forall x \in (a,b)$， $g’(x) \ne 0$, 则 $\exists\xi \in (a,b)$, 使得</p>
<p>$$ \frac{f(b) - f(a)}{g(b) - g(a)} = \frac{f’(\xi)}{g’(\xi)}$$</p>
<h4 id="泰勒公式"><a href="#泰勒公式" class="headerlink" title="泰勒公式"></a>泰勒公式</h4><p>$f(x)$ 在 $x_0$ 处 $n$ 阶可导，则</p>
<p>$$  f(x) = f(x_0) + f’(x_0)(x-x_0) + \frac{f’’(x_0)}{2!}(x-x_0)^2 + … + \frac{f^{(n)}(x_0)}{n!}(x-x_0)^n + R_n(x)<br>$$</p>
<p>$R_n(x)$ 称为余项</p>
<ul>
<li><strong>偑亚诺余项</strong> $R_n(x) = o((x-x_0)^n)$,</li>
<li><strong>拉格朗日余项</strong> , $\xi$ 在 $x_0$ 与 $x$ 之间</li>
</ul>
<p>$$R_n(x)=\frac{f^{n+1}(\xi)}{(n+1)!}(x-x_0)^{n+1}$$</p>
<h4 id="有界性定理"><a href="#有界性定理" class="headerlink" title="有界性定理"></a>有界性定理</h4><p>函数连续则有界</p>
<h4 id="介值定理"><a href="#介值定理" class="headerlink" title="介值定理"></a>介值定理</h4><p>$f(x)$ 在 $[a,b]$ 上连续，则存在一个介于 $f(a) \sim f(b)$ 的值</p>
<h5 id="根-零点存在定理"><a href="#根-零点存在定理" class="headerlink" title="根/零点存在定理"></a>根/零点存在定理</h5><p>如果 $f(x)$ 在 $[a,b]$ 连续，且 $f(a) \cdot f(b) &lt; 0$， 则 $f(x) = 0$ 存在根，如果 $f(x)$ 单调，则只存在一个根。</p>
<h4 id="可积的充要条件"><a href="#可积的充要条件" class="headerlink" title="可积的充要条件"></a>可积的充要条件</h4><p>满足以下条件之一：</p>
<ul>
<li>f(x) 连续（则原函数可导）</li>
<li>单调有界</li>
<li>只有有限个第一类间断点且有界</li>
</ul>
<h4 id="定积分的性质"><a href="#定积分的性质" class="headerlink" title="定积分的性质"></a>定积分的性质</h4><h5 id="（定）积分中值定理"><a href="#（定）积分中值定理" class="headerlink" title="（定）积分中值定理"></a>（定）积分中值定理</h5><p>$f(x)$ 在 $[a,b]$ 上连续，则存在 $\xi \in (a,b)$</p>
<p>$$\int_a^b f(x) dx = f(\xi) (b-a)$$</p>
<h5 id="估值定理"><a href="#估值定理" class="headerlink" title="估值定理"></a>估值定理</h5><p>设 M 与 m 分别为 f(x) 在 [a,b] 上的最大最小值，则</p>
<p>$$ m(b-a) \le \int_a^b f(x) dx  \le M(b-a) $$</p>
<h5 id="保号性"><a href="#保号性" class="headerlink" title="保号性"></a>保号性</h5><p>如果在 [a,b] 上 $f(x) \ge 0$， 则 $\int_a^b f(x) dx \ge 0$</p>
<p>推论1， <strong>保序性</strong>： 如果在 [a,b] 上 $f(x) \ge g(x)$， 则 $\int_a^b f(x) dx \ge \int_a^b g(x) dx$</p>
<p>推论2： $\int_a^b |f(x)| dx \ge |\int_a^b f(x) dx|$</p>
<h5 id="区间可加性"><a href="#区间可加性" class="headerlink" title="区间可加性"></a>区间可加性</h5><p>不论 a,b,c 三点相对位置，恒有 $\int_a^b f(x) dx = \int_a^c f(x) dx + \int_c^b f(x) dx$</p>
<h5 id="线性性"><a href="#线性性" class="headerlink" title="线性性"></a>线性性</h5><p>$\int_a^b [k_1 f(x)+k_2 g(x)] dx = k_1 \int_a^b f(x) dx + k_2 \int_a^b g(x) dx$</p>
<h4 id="奇偶函数的导函数"><a href="#奇偶函数的导函数" class="headerlink" title="奇偶函数的导函数"></a>奇偶函数的导函数</h4><p>奇函数的导数为偶函数，偶函数的导数为奇函数</p>
<h4 id="极限的性质"><a href="#极限的性质" class="headerlink" title="极限的性质"></a>极限的性质</h4><h5 id="（局部）有界性"><a href="#（局部）有界性" class="headerlink" title="（局部）有界性"></a>（局部）有界性</h5><p>若 $lim_{x \rightarrow x_0} f(x) = A$, 则 $\exists\;M&gt;0,\;\delta &gt; 0$，对 $\forall\; x \in U^\circ(x_0, \delta)$， 都有 $|f(x)| \le M$</p>
<h5 id="局部保号性"><a href="#局部保号性" class="headerlink" title="局部保号性"></a>局部保号性</h5><p>若 $lim_{x \rightarrow x_0} f(x) = A &gt; 0$ （或 $<0$ ）,="" 则="" $\exists="" \delta="">0$， 使得对 $\forall x \in U^\circ(x_0,\delta)$， 都有 $f(x) &gt; 0\;(&lt;0)$</0$></p>
<h4 id="极限存在准则"><a href="#极限存在准则" class="headerlink" title="极限存在准则"></a>极限存在准则</h4><h5 id="夹逼准则"><a href="#夹逼准则" class="headerlink" title="夹逼准则"></a>夹逼准则</h5><p>若在 $x_0$ 的某个空心邻域 $(x_0,\delta<em>0)$ 内，有 $g(x) \le f(x) \le h(x)$ ，且 $\lim</em>{x\rightarrow x<em>0} g(x) =lim</em>{x\rightarrow x<em>0} h(x)=A$， 则 $lim</em>{x\rightarrow x_0} f(x)=A$</p>
<h5 id="单调有界准则"><a href="#单调有界准则" class="headerlink" title="单调有界准则"></a>单调有界准则</h5><p>单调有界数列必有极限，包括单调增加有上界，单调减少有下界两种情况</p>
<h4 id="隐函数存在定理（一个方程）"><a href="#隐函数存在定理（一个方程）" class="headerlink" title="隐函数存在定理（一个方程）"></a>隐函数存在定理（一个方程）</h4><p>设方程 $F(x,y)=0$ 的左端函数 $F(x,y)$ 满足</p>
<ul>
<li>在点 $P_0(x_0,y_0)$ 的某一邻域内具有连续的偏导数 $F_x,\; F_y$</li>
<li>$F(x_0,y_0)=0$</li>
<li>$F_y(x_0,y_0)\ne 0$</li>
</ul>
<p>则在点 $P_0(x_0, y_0)$ 的某一邻域内，由方程 $F(x,y)=0$ 唯一确定单值连续且有连续导数的函数 $y=f(x)$， 使得 $F(x, f(x)) \equiv 0$， 且 $y_0=f(x_0)$ 并有：</p>
<p>$$ \frac{dy}{dx} = -\frac{F_x}{F_y} $$</p>
<p>可推广到多元隐函数</p>
<h4 id="偏导数与梯度"><a href="#偏导数与梯度" class="headerlink" title="偏导数与梯度"></a>偏导数与梯度</h4><p>单位向量 $\mathbf{l}(\cos \alpha, \cos \beta)$ 的偏导数</p>
<p>$$ \frac{\partial f}{\partial l} = (\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}) \cdot (\cos \alpha, \cos \beta) = \mathbf{grad } f \cdot \mathbf{l} = ||\mathbf{grad} f|| \cdot \cos \theta $$</p>
<p>其中 $\theta$ 为梯度 $\mathbf{grad} f$ 与方向向量 $\mathbf{l}$ 的夹角。有以下结论：</p>
<ul>
<li>方向导数沿梯度方向取得最大值 $||\mathbf{grad}f||$</li>
<li>方向导数沿梯度反方向取得最小值 $-||\mathbf{grad}f||$</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/26/ML-MLT-4-kernelLogisticRegression/" itemprop="url">
                  机器学习技法第五课——Kernel Logistic Regression
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-26T23:32:41+08:00" content="2016-06-26">
              2016-06-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是学习林轩田老师的机器学习技法第五课——Kernel Logistic Regression——的课程笔记。</p>
<p>这节课主要讨论了 SVM 与 Logistic 回归的相似性，其目标是解决“SVM 从 0/1 分类到概率分类的转换”以及“Logistic 从低维空间到高维空间的转换”，提出了二个方法，一是，将 SVM 训练结果代入 Logistic 中训练，二是，使用 Logistic Regression 的 kernel 模型进行训练。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="/2016/06/09/ML-MLT-3-softSVM/" title="Soft Margin SVM">Soft Margin SVM</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/205_handout.pdf" target="_blank" rel="noopener">课件</a></li>
<li><a href="https://en.wikipedia.org/wiki/Platt_scaling" target="_blank" rel="noopener">Platt scaling</a></li>
<li><a href="/2016/06/05/ML-MLT-2-kernelSVM/" title="Kernel SVM">Kernel SVM</a>
</li>
</ul>
<h3 id="SVM-与-L2-正则化"><a href="#SVM-与-L2-正则化" class="headerlink" title="SVM 与 L2 正则化"></a>SVM 与 L2 正则化</h3><p>推导 <a href="/2016/06/09/ML-MLT-3-softSVM/" title="Soft Margin SVM">Soft Margin SVM</a> 的原始公式：<br>$$  \min<em>{b,\mathbf{w},\xi} \frac{1}{2}\mathbf{w^Tw} + C \sum</em>{n=1}^{N}\xi_n \\<br>s.t.\ y_n(\mathbf{w^Tz_n} + b) \ge 1 - \xi_n \\<br>s.t.\ \xi_n \ge 0<br>$$<br>$\xi$ 是松弛变量，也可视作 err，衡量越过 Margin 或分类超平面的程度，大致可以写成 $err = \xi_n = \max{(1-y_n(w^T z<em>n + b),\; 0)}$, 原式大概可以写成：<br>$$  \min</em>{b,\mathbf{w}} \frac{1}{2}\mathbf{w^Tw} + C \sum_{n=1}^{N}{\max{(1-y_n(w^T z_n + b),\; 0)}}<br>$$<br>$$即\;\min{\frac{1}{2}\mathbf{w^Tw} + C\sum{err}}$$<br>这个公式与<a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习基石</a>部分的带 L2 正则化的 PLA 算法比较相似。SVM 大致可以视作一个带 L2 正则化的分类器。（这个 error 常被称作 hinge loss）</p>
<h3 id="SVM-与-Logistic-相似"><a href="#SVM-与-Logistic-相似" class="headerlink" title="SVM 与 Logistic 相似"></a>SVM 与 Logistic 相似</h3><p>令 $s=w^T z + b$ （超平面分类得分），引入<a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习基石</a>中的 0/1 错误、 Logistic 回归的错误与 SVM 错误比较：</p>
<table>
<thead>
<tr>
<th style="text-align:center">err type</th>
<th style="text-align:center">function</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0/1</td>
<td style="text-align:center">[$ys \le 0$]</td>
</tr>
<tr>
<td style="text-align:center">logistic</td>
<td style="text-align:center">$\ln(1+\exp(-ys))$</td>
</tr>
<tr>
<td style="text-align:center">SVM</td>
<td style="text-align:center">$\max(1-ys,\; 0)$</td>
</tr>
</tbody>
</table>
<p>课程中作图更直观，在此就大致解释下 ：P。 $y, s$ 同号时，分类正确，0/1 分类中 “[]” 表示 bool 判断，如果 $ys \le 0$ 取1，反之取0，即分类正确 err 为 0，错误取 1 以记录错误。与之不同的是，Logistic 与 SVM 在分类错误时，不止记录了错误，而且在 $ys$ 越小时，err 取值越大。在分类正确时，后两者要么直接取 0，要么取一个 $0 \sim 1$ 的数。Logistic 与 SVM 都放大了分类错误数据的影响，而忽略分类正确数据的影响。</p>
<h3 id="Platt’s-scaling"><a href="#Platt’s-scaling" class="headerlink" title="Platt’s scaling"></a>Platt’s scaling</h3><p><a href="https://en.wikipedia.org/wiki/Platt_scaling" target="_blank" rel="noopener">Platt scaling</a> 又称 Platt calibration，将分类模型对数据的预测评分作为输入，训练 Logistic 模型，将它转化成概率模型。运用这个方法将 SVM 与 Logistic 结合，使得 SVM 拥有概率特征，而 Logistic 可以用 SVM kernel 处理多维空间转换。大致过程为</p>
<ul>
<li>run SVM get $\Phi_{svm}(z_n) = w^T z_n + b$</li>
<li>run Logistic problem get A, B:<br>$$  \min<em>{A, B} {\frac{1}{N} \sum</em>{n=1}^{N}{ \ln{(1 + \exp(-y<em>n (A \Phi</em>{svm}(z_n) + B)))} }}<br>$$<br>这里 A 是对 SVM 模型的一个放缩，对结果影响不大，而 B 有对原 SVM 有一定影响，应该尽量接近 0。在课程中，将这个模型称为 probabilistic SVM。</li>
</ul>
<h3 id="Kernel-Logistic-Regression"><a href="#Kernel-Logistic-Regression" class="headerlink" title="Kernel Logistic Regression"></a>Kernel Logistic Regression</h3><p>这一部分试图推导出 Logistic 的 kernel，以解决 Logistic 向高维空间映射的问题。提前声明一下，由于此模型不具有 SVM 的稀疏性，林老师在下节课会说明此方法相对 Platt’s scaling 较少使用。</p>
<p>首先，对于以下形式的“带 L2 正则化的线性模型”<br>$$  \min<em>{\mathbf{w}} \frac{\lambda}{N}\mathbf{w^Tw} + \frac{1}{N} \sum</em>{n=1}^{N}{err(y_n, w^T z<em>n)}<br>$$<br>老师用奇妙的方法证明了其中的 $\mathbf{w}$ 可以被 $\mathbf{z}$ 线性表示<br>$$\mathbf{w} = \sum</em>{n=1}^N \beta_n z_n$$<br>，而且该模型能被转换成 kernel 形式。（至于如何证明的，因为十分奇妙在此略过 ：P）</p>
<p>当然，带 L2 正则化的 Logistic 回归模型符合以上条件。<br>$$  \min<em>{w} { \frac{\lambda}{N}\mathbf{w^Tw}  +\frac{1}{N} \sum</em>{n=1}^{N}{ \ln{(1 + \exp(-y_n w^T z_n))} }}<br>$$</p>
<p>在 <a href="/2016/06/05/ML-MLT-2-kernelSVM/" title="Kernel SVM">Kernel SVM</a> 中，用 kernel 函数 $K(\mathbf{x, x’})$ 替换 $\mathbf{z^Tz’}$，所以，接下来要把高维空间的 $\mathbf{w, z}$ 用 kernel 替换。<br>$$ \mathbf{w^Tw} = \sum<em>{n=1}^{N}\sum</em>{n=1}^{M} \beta_n \beta_m K(\mathbf{x_n, x_m})\quad （向量内积分配律）\\<br> \mathbf{w^Tz<em>n} = \sum</em>{m=1}^N {\beta_m K(\mathbf{x_m, x_n})}<br>$$</p>
<p>最后问题变成求解 $\beta$<br>$$  \min<em>{w} { \frac{\lambda}{N} \sum</em>{n=1}^{N}\sum_{n=1}^{M} \beta_n \beta_m K(\mathbf{x_n, x<em>m})<br> +\frac{1}{N} \sum</em>{n=1}^{N}{ \ln{(1 + \exp(-y<em>n \sum</em>{m=1}^N {\beta_m K(\mathbf{x_m, x_n})}))} }}<br>$$<br>需要说明，$\beta$ 往往非 0，而对比 SVM 中的 $\alpha$，则大多是 0（非支持向量），后者具有稀疏性。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/09/ML-MLT-3-softSVM/" itemprop="url">
                  机器学习技法第四课——Soft-Margin SVM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-09T18:31:14+08:00" content="2016-06-09">
              2016-06-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是本人学习林轩田老师的机器学习技法第四课——Soft-Margin Support Vector Machine——的课堂笔记。</p>
<p>前几节课的 SVM 不能容忍错误——包括不可分错误及可分分却在 margin 内的错误，这节课要解决这个问题，推导出 Soft Margin SVM。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/204_handout.pdf" target="_blank" rel="noopener">课件</a></li>
<li><a href="http://taop.marchtea.com/07.02.svm.html" target="_blank" rel="noopener">支持向量机</a></li>
<li><a href="/2016/05/31/ML-MLT-1-dualSVM/" title="Dual Support Vector Machine">Dual Support Vector Machine</a>
</li>
</ul>
<h3 id="松弛变量"><a href="#松弛变量" class="headerlink" title="松弛变量"></a>松弛变量</h3><p>引入松弛变量 $\xi$，放宽条件，同时避免过度放宽，在最小化公式中也加入 $\xi$：<br>$$  \min<em>{b,\mathbf{w},\xi} \frac{1}{2}\mathbf{w^Tw} + C \sum</em>{n=1}^{N}\xi_n \\<br>s.t.\ y_n(\mathbf{w^Tz_n} + b) \ge 1 - \xi_n \\<br>s.t.\ \xi_n \ge 0<br>$$<br>此处 $C$ 是一个常量，作为平衡“large margin”与”margin violation”的参数。<br>$\xi$ 在限制条件中确实减小了下限，放宽了条件，但至于这背后为何能使 SVM 容忍错误，这可能要从头开始推导了。很明显，这已经可以用二次规划求解。</p>
<h3 id="对偶问题"><a href="#对偶问题" class="headerlink" title="对偶问题"></a>对偶问题</h3><p>转换成对偶问题，用前面课程 <a href="/2016/05/31/ML-MLT-1-dualSVM/" title="Dual Support Vector Machine">Dual Support Vector Machine</a> 中同样的方法。</p>
<h4 id="拉格朗日乘数"><a href="#拉格朗日乘数" class="headerlink" title="拉格朗日乘数"></a>拉格朗日乘数</h4><p>$$  L(b,\mathbf{w},\alpha,\beta) = \frac{1}{2}\mathbf{w^Tw} + C \sum_{n=1}^{N}\xi<em>n + \sum</em>{n=1}^N \alpha_n(1-\xi_n-y_n(\mathbf{w^T z<em>n} + b)) + \sum</em>{n=1}^N \beta_n (-\xi<em>n)<br>$$<br>求解：<br>$$   \max</em>{\alpha_n \ge 0,\ \beta<em>n \ge 0} (min</em>{b,\mathbf{w},\xi} L(b,\mathbf{w},\alpha,\beta))<br>$$</p>
<h4 id="求导化简成关于-alpha-的函数"><a href="#求导化简成关于-alpha-的函数" class="headerlink" title="求导化简成关于 $\alpha$ 的函数"></a>求导化简成关于 $\alpha$ 的函数</h4><p>$$    \frac{\partial L}{\partial \xi_n} = C - \alpha_n - \beta_n\\<br>let\ \ \beta_n= C -\alpha_n<br>$$<br>因为条件中有 $\alpha_n \ge 0$，故 $C \ge \alpha<em>n \ge 0$。如此原式变换为：<br>$$    \max</em>{$0 \le \alpha_n \le C,\ \beta_n=C-\alpha<em>n} (\min</em>{b,\mathbf{w},\xi} \frac{1}{2} \mathbf{w^T w} + \sum_{n=1}^{N}\alpha_n(1 - y_n(\mathbf{w^T \mathbf{z_n}} + b)))<br>$$<br>这一步增加了限制条件，但消去了 $\beta, \xi, C$。接下来与 <a href="/2016/05/31/ML-MLT-1-dualSVM/" title="Dual Support Vector Machine">Dual Support Vector Machine</a> 的过程相同，令 $\frac{\partial L}{\partial b} = 0, \frac{\partial L}{\partial w<em>i} = 0$ 化简得：<br>$$<br>\min</em>{\alpha<em>n} (\frac{1}{2}\sum</em>{m=1}^{N} \sum_{n=1}^{N} y_m  y_n \mathbf{z_m^T} \mathbf{z_n} \alpha_m \alpha<em>n - \sum</em>{n=1}^{N}\alpha<em>n) \\<br>s.t.\ \ \sum</em>{n=1}^N y_n \alpha_n = 0,\ \ all\ 0 \le \alpha_n \le C<br>$$<br>看上去与之前的差别只有对 $\alpha$ 加上上限 C。</p>
<h4 id="求解-b"><a href="#求解-b" class="headerlink" title="求解 $b$"></a>求解 $b$</h4><p>部分 KKT 条件：<br>$$  \alpha_n(1-\xi_n-y_n(\mathbf{w^T z_n} + b)) = 0 \\<br>(C - \alpha_n) \xi_n = 0  $$<br>因为除 $\xi,\ b$ 其他都是已知量，所以只要求解方程组就能得到解。而多数情况下，当 $0 \lt \alpha_n \lt C$ 时，被称为 free Support Vector，可推导出<br>$$  b = y_s - \mathbf{w^T z_s}<br>$$<br>之后的求解过程与前面课程没什么不同。</p>
<h3 id="alpha-n-与向量角色"><a href="#alpha-n-与向量角色" class="headerlink" title="$\alpha_n$ 与向量角色"></a>$\alpha_n$ 与向量角色</h3><p>根据 KKT 条件，当 $\alpha_n = 0$ 时，松弛变量 $\xi_n=0$，没有错误，被称为非支持向量，<strong><em>non SV</em></strong>，处于 margin 外界；</p>
<p>当 $0 \lt \alpha \lt C$ 时，$\xi_n=0$，没有错误，而且可以求解 $b$，被称为 <strong><em>free SV</em></strong>，位于 margin 上；</p>
<p>当 $\alpha = C$ 时， $\xi_n \ne 0$，有错误，同样可以帮助求解，被称为 <strong><em>bounded SV</em></strong>，位于 margin 内部或越过了超平面。</p>
<h3 id="LOOC-帮助模型选择"><a href="#LOOC-帮助模型选择" class="headerlink" title="LOOC 帮助模型选择"></a>LOOC 帮助模型选择</h3><p>模型选择时，可以用 Cross Validation 做参考，其中特别的有 Leave-One-Out CV，即只留一个数据点做验证。</p>
<p>将 Leave-One-Out CV 与全数据集（不留验证数据）的训练做比较。如果验证数据是一个 non-SV，那么，2 者的错误是相同的，而如果验证数据是一个 SV，那么有可能分类错误。所以有<br>$$  E_{loocv} \le \frac{num(SV)}{N} $$<br>这里存在疑问的是，如果验证数据是一个很关键的 SV，可能极大地影响超平面的训练结果，这个 bound 是否成立。</p>
<p>这个上限可以用做安全检查，在训练模型之后便能得到 $E_{loocv}$ 的上限，可以排除一些结果太差的模型，节省时间，但它的作用有限，不能断定一个模型的好坏。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/07/Algo-asymptoticAnalysis/" itemprop="url">
                  算法时间复杂度
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-07T21:07:37+08:00" content="2016-06-07">
              2016-06-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Algo/" itemprop="url" rel="index">
                    <span itemprop="name">Algo</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Coursera 上 <a href="https://class.coursera.org/algo-009/lecture" target="_blank" rel="noopener">Algorithms: Design and Analysis, Part 1 by Tim Roughgarden</a> 的学习笔记。第二课，有关时间复杂度。</p>
<h4 id="The-Gist"><a href="#The-Gist" class="headerlink" title="The Gist"></a>The Gist</h4><p>时间复杂度计算概略地讲，就是“suppress constant factors and lower-order terms”</p>
<h4 id="Big-Oh-Notation"><a href="#Big-Oh-Notation" class="headerlink" title="Big-Oh Notation"></a>Big-Oh Notation</h4><p>Formal Definition: $T(n) = O(f(n))$ \<br>if and only if exist constants $c, n_0$ such that $T(n) \le cf(n)$ \<br>for all $n \gt n_0$</p>
<p>即 $n \rightarrow +\infty$ 时，$cf(n)$ 为 $T(n)$ 上限</p>
<h4 id="Omega-Notation"><a href="#Omega-Notation" class="headerlink" title="Omega Notation"></a>Omega Notation</h4><p>Formal Definition: $T(n) = \Omega(f(n))$ \<br>if and only if exist constants $c, n_0$ such that $T(n) \ge cf(n)$ \<br>for all $n \gt n_0$</p>
<p>即 $n \rightarrow +\infty$ 时，$cf(n)$ 为 $T(n)$ 下限</p>
<h4 id="Theta-Notation"><a href="#Theta-Notation" class="headerlink" title="Theta Notation"></a>Theta Notation</h4><p>Formal Definition: $T(n) = \Theta(f(n))$ \<br>if and only if $T(n)=O(f(n))$ and $\Omega(n)=O(f(n))$</p>
<p>即 $n \rightarrow +\infty$ 时，$cf(n)$ 既能作 $T(n)$ 下限也能作上限，</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/05/ML-MLT-2-kernelSVM/" itemprop="url">
                  机器学习技法第三课——Kernel SVM
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-05T21:45:49+08:00" content="2016-06-05">
              2016-06-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index">
                    <span itemprop="name">ML</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>此文是学习林轩田老师的机器学习技法第三课——Kernel Support Vector Machine——的课堂笔记。</p>
<p>给定上节课的公式：<br>$$<br>\min_{\alpha<em>n} (\frac{1}{2}\sum</em>{m=1}^{N} \sum_{n=1}^{N} y_m y_n \mathbf{z_m^T}  \mathbf{z_n} \alpha_m \alpha<em>n - \sum</em>{n=1}^{N}\alpha_n) \\<br>s.t.\ all\ \alpha<em>n \ge 0,\ \sum</em>{n=1}^N \alpha_n y_n = 0<br>$$<br>这里 $\mathbf{z}$ 是由 $\mathbf{x}$ 变换得到。在 $\mathbf{x}$ 向量所处的空间里，如果所有超平面都不能对数据进行分类，可以将 $\mathbf{x}$ 映射到高维空间，也就是 $\mathbf{x}$ 变换成 $\mathbf{z}$。这次课的目标包括：了解这种变换带来的求解问题，引入核函数、多项式核函数、高斯核函数，及了解如何选择核 SVM 或线性 SVM。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/" target="_blank" rel="noopener">机器学习技法</a></li>
<li><a href="/2016/05/31/ML-MLT-1-dualSVM/" title="Dual Support Vector Machine">Dual Support Vector Machine</a></li>
<li><a href="https://www.csie.ntu.edu.tw/~htlin/mooc/doc/203_handout.pdf" target="_blank" rel="noopener">课件</a></li>
</ul>
<h3 id="求解复杂度"><a href="#求解复杂度" class="headerlink" title="求解复杂度"></a>求解复杂度</h3><p>考虑将 $\mathbf{x}$ 从一次变换到二次：<br>$$\mathbf{x} = (x_1, x_2, …, x_d) \ \ \rightarrow \\<br>\mathbf{z} = (1, x_1, x_2, …, x_d, x_1 x_1, x_1 x_2, …, x_1 x_d, x_2 x_1, x_2 x_2, …, x_2 x_d, …, x_d x_d)$$</p>
<p>向量长度增加了 $d^2 + 1$，由于在求解公式中需要计算任意2个 $\mathbf{x}$ 的内积（$\mathbf{z_m^T z_n}$），计算复杂度从 $o(d^2)$ 增加到 $o(d^4)$，陡增了不少困难。而这仅是变换到二次的情况。</p>
<h3 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h3><p>就 <strong><em>求解复杂度</em></strong> 一节所举一次变二次，有以下推导：<br>$$\mathbf{z^T z’} = 1 + \sum_{i=1}^d x_i x’<em>i + \sum</em>{i=1}^d \sum_{j=1}^d x_i x_j x’_i x’<em>j \\<br>=1 + \sum</em>{i=1}^d x_i x’<em>i + (\sum</em>{i=1}^d x_i x’<em>i) (\sum</em>{j=1}^d x_j x’_j) \\<br>=1 + \mathbf{x^T x’} + (\mathbf{x^T x’})(\mathbf{x^T x’})$$<br>可见任意2个 $\mathbf{w}$ 的内积（$\mathbf{z^T z’}$）可以用 $\mathbf{x}$ 的内积表示。这可以推广到更高次变换。</p>
<p>这种处理有何好处？复杂度大幅降低，从原来的 $o(d^4)$ 回降到 $o(d^2)$。</p>
<h4 id="核函数-1"><a href="#核函数-1" class="headerlink" title="核函数"></a>核函数</h4><p>简单来说，核函数（核）应该是：<br>$$\mathbf{z^T z’} = K(\mathbf{x}, \mathbf{x’})$$<br>在一次变二次例子中 $K(\mathbf{x}, \mathbf{x’}) =1 + \mathbf{x^T x’} + (\mathbf{x^T x’})(\mathbf{x^T x’})$。</p>
<p>原求解公式变换为：<br>$$<br>\min_{\alpha<em>n} (\frac{1}{2}\sum</em>{m=1}^{N} \sum_{n=1}^{N} y_m y_n K(\mathbf{x}_m, \mathbf{x}_n) \alpha_m \alpha<em>n - \sum</em>{n=1}^{N}\alpha_n) \\<br>s.t.\ all\ \alpha<em>n \ge 0,\ \sum</em>{n=1}^N \alpha_n y_n = 0<br>$$<br>设 $(\mathbf{x}_s, y_s)$ 为支持向量（$\alpha_s = 0$）解出 $b$:<br>$$<br>b = y_s - \mathbf{w^T \mathbf{z_s}} \\<br>= y<em>s - (\sum</em>{n=1}^{N} \alpha_n y_n \mathbf{z_n})^\mathbf{T} \mathbf{z}_s \\<br>= y<em>s - \sum</em>{n=1}^{N} \alpha_n y_n K(\mathbf{x}_n, \mathbf{x}<em>s)<br>$$<br>求解 $\mathbf{w}$ 似乎有点复杂，但不影响最终分类。分类公式变换为<br>$$g</em>{svm}(\mathbf{x}) = sign(\mathbf{w^T z} + b)<br>=sign(\sum_{n=1}^{N} \alpha_n y_n K(\mathbf{x}_n, \mathbf{x}) + b)$$</p>
<h4 id="多项式核函数"><a href="#多项式核函数" class="headerlink" title="多项式核函数"></a>多项式核函数</h4><p>$$K(\mathbf{x}, \mathbf{x’}) = (\zeta + \gamma \mathbf{x^T x’})^q,\ with\ \zeta \ge 0,\ \gamma \gt 0$$<br>例如，当 $q = 2$ 时，<br>$$\mathbf{z^T z’} = K(\mathbf{x}, \mathbf{x’}) =1 + 2\zeta\gamma\mathbf{x^T x’} + \gamma^2(\mathbf{x^T x’})^2 \\<br>\Rightarrow \mathbf{z} = (1, \sqrt{2\zeta\gamma}x_1,  \sqrt{2\zeta\gamma}x_2, …,  \sqrt{2\zeta\gamma}x_n, \gamma x_1 x_1, \gamma x_1 x_2, …, \gamma x_n x_n)$$<br>感觉这个核不能满足所有从 $\mathbf{x}$ 到 $\mathbf{z}$ 的多项式变换，比如 $\mathbf{z}$ 中至少所有一次项系数都相等（在上例中为 $\sqrt{2\zeta\gamma}$）。</p>
<h4 id="高斯核函数"><a href="#高斯核函数" class="headerlink" title="高斯核函数"></a>高斯核函数</h4><p>$$K(\mathbf{x}, \mathbf{x’}) = exp(-\gamma |\mathbf{x - x’}|^2),\ with\ \gamma \gt 0$$<br>高斯（Gaussian）核函数可以将 $\mathbf{x}$ 扩展到无限维。</p>
<p>课上只给了 $\gamma = 1,\ \mathbf{x} = (x)$（$\mathbf{x}$ 只有一个维度）时的推导：<br>$$K(\mathbf{x}, \mathbf{x’}) = exp(-(\mathbf{x - x’})^2) \\<br>=exp(-x^2)exp(-x’^2)exp(2xx’)\\<br>=exp(-(x)^2)exp(-(x’)^2) \sum<em>{i=0}^\infty \frac{(2xx’)^i}{i!},\ \ taylor\ expansion \\<br>=\sum</em>{i=0}^\infty(exp(-x^2)exp(-x’^2) \sqrt{\frac{2^i}{i!}} \sqrt{\frac{2^i}{i!}} x^i x’^i) \\<br>=\mathbf{z^T z’} \\<br>with\ \mathbf{z}=exp(-x^2)(1, \sqrt{\frac{2}{1!}} x, \sqrt{\frac{2^2}{2!}}x^2, …)<br>$$</p>
<p>如果 $\gamma$ 取值过大（方差过大），高斯核会过拟合。</p>
<h3 id="核函数并非万能"><a href="#核函数并非万能" class="headerlink" title="核函数并非万能"></a>核函数并非万能</h3><p>线性 SVM 指原始的，$\mathbf{x}$ 未经变换的 SVM，求解相对多项式核 SVM 简单（系数矩阵为对角矩阵），而且，参数选择较少。而高斯核的模型难以解释，且容易过拟合。</p>
<p>对于高次的多项式 kernel，可以考虑用原始的方法，将 $\mathbf{x}$ 转化成 $\mathbf{z}$ 之后代入线性 SVM 求解，如果维度不高，求解速度会更快。</p>
<h3 id="其他核函数"><a href="#其他核函数" class="headerlink" title="其他核函数"></a>其他核函数</h3><p>课上指出，能成为核函数的充要条件是，核函数导出的矩阵 $\mathbf{K}$，$k_{i,j}=K(\mathbf{x_i, x_j})$，是对称且半正定的。这2个条件被称为 Mercer’s condition。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/03/Python-cheatSheet/" itemprop="url">
                  Python 杂记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-03T10:58:50+08:00" content="2016-06-03">
              2016-06-03
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Tools/" itemprop="url" rel="index">
                    <span itemprop="name">Tools</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="http://blog.csdn.net/sasoritattoo/article/details/12451359" target="_blank" rel="noopener">python代码 `if not x:` 和`if x is not None:`和`if not x is None:`使用</a></li>
<li><a href="http://www.2cto.com/kf/201405/300359.html" target="_blank" rel="noopener">python变量和作用域</a></li>
<li><a href="http://www.cnblogs.com/ifantastic/archive/2013/04/15/3021845.html" target="_blank" rel="noopener">Python 序列的切片操作与技巧</a></li>
</ul>
<h3 id="函数和常用语法"><a href="#函数和常用语法" class="headerlink" title="函数和常用语法"></a>函数和常用语法</h3><h4 id="raw-input-与-input"><a href="#raw-input-与-input" class="headerlink" title="raw_input 与 input"></a>raw_input 与 input</h4><p><code>raw_input</code> 只在 2 中存在，返回字符串，在 2 中，<code>input</code> 返回输入表达式的值；\<br>3 中 input 返回字符串。</p>
<h4 id="type"><a href="#type" class="headerlink" title="type"></a>type</h4><p>查看变量类型</p>
<h4 id="交换两变量值"><a href="#交换两变量值" class="headerlink" title="交换两变量值"></a>交换两变量值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure>
<h4 id="while-for-else-语句"><a href="#while-for-else-语句" class="headerlink" title="while/for else 语句"></a>while/for else 语句</h4><p>跟 if else 相同，在 while/for 条件为假时执行 else。所以，在未进入循环或循环正常完成后，else 部分会执行，而循环被 break 或出现异常，则不会执行 else。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> value <span class="keyword">in</span> [<span class="string">"Sat"</span>,<span class="string">"Sun"</span>,<span class="string">"Mon"</span>]:</span><br><span class="line">  <span class="keyword">if</span> value == <span class="string">"Sun"</span>:</span><br><span class="line">    print(<span class="string">"Bingo!"</span>)</span><br><span class="line">    <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">  print(<span class="string">"No Sunday."</span>)</span><br></pre></td></tr></table></figure>
<h4 id="yield-关键字"><a href="#yield-关键字" class="headerlink" title="yield 关键字"></a>yield 关键字</h4><p>在函数中使用 yield 关键字让函数返回一个 <strong>生成器</strong>。 该生成器调用方式十分奇特，类似于断点调试，在调用其 <code>next()</code> 方法时运行到 yield 关键字处并返回参数，可多次调用直到函数结束（抛出 StopIteration 异常）。可以在函数中使用多个 yield，就像设置多个断点。隐含的一个特性是，每次只能取到下一个值，而不能回退取到上一个值。通常用 <code>for/while</code> 循环使用生成器，以代替循环调用 <code>next()</code>，</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span><span class="params">(stop)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"step in"</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(stop):</span><br><span class="line">        <span class="keyword">yield</span> i  <span class="comment"># 当代码运行到此处返回 i</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"yield %g"</span> % i</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">g = gen(<span class="number">3</span>)  <span class="comment"># 函数返回一个生成器</span></span><br><span class="line"><span class="keyword">print</span> <span class="string">"called gen"</span>  <span class="comment"># 在调用 g.next() 方法前，gen 内代码不会执行</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> g:</span><br><span class="line">    <span class="keyword">print</span> i</span><br></pre></td></tr></table></figure>
<h4 id="sign-函数"><a href="#sign-函数" class="headerlink" title="sign 函数"></a>sign 函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sign = <span class="keyword">lambda</span> a: <span class="number">1</span> <span class="keyword">if</span> a &gt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">-1</span> <span class="keyword">if</span> a &lt; <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<h4 id="print-不换行"><a href="#print-不换行" class="headerlink" title="print 不换行"></a>print 不换行</h4><p>python2 中 print 不换行，python3 中使用参数 <code>end=&#39;&#39;</code><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"Hello World"</span>, end=<span class="string">''</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="dict-键列表"><a href="#dict-键列表" class="headerlink" title="dict 键列表"></a>dict 键列表</h4><p>使用 <code>list(dict)</code> 获取 <code>dict</code> 的键列表</p>
<h3 id="惯用处理"><a href="#惯用处理" class="headerlink" title="惯用处理"></a>惯用处理</h3><h4 id="pip-更换仓库源"><a href="#pip-更换仓库源" class="headerlink" title="pip 更换仓库源"></a>pip 更换仓库源</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install numpy -i http://pypi.mirrors.ustc.edu.cn/simple/ <span class="comment"># 临时用中科大源安装numpy</span></span><br></pre></td></tr></table></figure>
<h4 id="pip-下载安装包并离线安装"><a href="#pip-下载安装包并离线安装" class="headerlink" title="pip 下载安装包并离线安装"></a>pip 下载安装包并离线安装</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 只下载包</span><br><span class="line">pip download -d ./download_packs_dir -r ./requirements.txt</span><br><span class="line"># 只安装</span><br><span class="line">pip install --no-index --find-links=./download_packs_dir -r ./requirements.txt</span><br></pre></td></tr></table></figure>
<h4 id="从文件路径获取文件名与扩展名"><a href="#从文件路径获取文件名与扩展名" class="headerlink" title="从文件路径获取文件名与扩展名"></a>从文件路径获取文件名与扩展名</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">filepath = <span class="string">'/tmp/log.txt'</span></span><br><span class="line">filename = os.path.basename(filepath) <span class="comment"># 文件名</span></span><br><span class="line">print(os.path.splitext(filename)) <span class="comment"># 分离扩展名</span></span><br></pre></td></tr></table></figure>
<h4 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h4><p>datetime 与 字符串相互转换<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line">id_s = <span class="string">"337259199211056344"</span>[<span class="number">6</span>:<span class="number">14</span>] <span class="comment"># 身份证号</span></span><br><span class="line">d = datetime.strptime(id_s, <span class="string">'%Y%m%d'</span>)</span><br><span class="line">print((datetime.now() - d).days)  <span class="comment"># 距今多少天，datetime相减得delta对象</span></span><br><span class="line">print(d.strftime(<span class="string">'%Y-%m-%d'</span>)) <span class="comment"># datetime 格式化输出字符串</span></span><br></pre></td></tr></table></figure></p>
<h4 id="判断对象为数字"><a href="#判断对象为数字" class="headerlink" title="判断对象为数字"></a>判断对象为数字</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numbers</span><br><span class="line">x = <span class="number">1</span></span><br><span class="line">print(isinstance(x, numbers.Number))</span><br></pre></td></tr></table></figure>
<h4 id="读-excel-表"><a href="#读-excel-表" class="headerlink" title="读 excel 表"></a>读 excel 表</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> xlrd</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_excel</span><span class="params">(excel_name, sheet_name)</span>:</span></span><br><span class="line">    bk = xlrd.open_workbook(excel_name)</span><br><span class="line">    sh = bk.sheet_by_name(sheet_name)</span><br><span class="line"></span><br><span class="line">    nrows = sh.nrows <span class="comment">#获取行数</span></span><br><span class="line">    ncols = sh.ncols <span class="comment">#获取列数</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"excel %s, sheet %s, nrows %d, ncols %d"</span> % (excel_name, sheet_name, nrows,ncols))</span><br><span class="line"></span><br><span class="line">    row_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, nrows):    <span class="comment">#获取各行数据</span></span><br><span class="line">        row_data = sh.row_values(i)</span><br><span class="line">        row_list.append(row_data)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> row_list</span><br></pre></td></tr></table></figure>
<h4 id="生成随机数"><a href="#生成随机数" class="headerlink" title="生成随机数"></a>生成随机数</h4><h5 id="random"><a href="#random" class="headerlink" title="random"></a>random</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line">random.random() <span class="comment"># 0 到 1 小数</span></span><br><span class="line">random.randint(m,n) <span class="comment"># m 到 n 整数</span></span><br><span class="line">random.sample(list, n) <span class="comment"># 从 list 不放回抽样 n 个，返回列表</span></span><br></pre></td></tr></table></figure>
<h5 id="正态随机"><a href="#正态随机" class="headerlink" title="正态随机"></a>正态随机</h5><p>生成正态随机数列可用<code>numpy.random.normal(mu, sigma, sample_num)</code></p>
<h4 id="正则"><a href="#正则" class="headerlink" title="正则"></a>正则</h4><p>匹配例子<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">str = <span class="string">"截止日期：2016-7-11 2:44:29。余额：137533。逾期金额：28747。"</span></span><br><span class="line">print(re.findall(<span class="string">r"余额：(.+?)。"</span>, str))</span><br></pre></td></tr></table></figure></p>
<h3 id="list-操作"><a href="#list-操作" class="headerlink" title="list 操作"></a>list 操作</h3><h4 id="range"><a href="#range" class="headerlink" title="range()"></a>range()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># range(stat=0,stop,step=1)</span></span><br><span class="line">range(<span class="number">10</span>) <span class="comment"># 返回 0 到 9 列表</span></span><br><span class="line">range(<span class="number">1</span>,<span class="number">10</span>) <span class="comment"># 返回 1 到 9 列表</span></span><br><span class="line">range(<span class="number">1</span>,<span class="number">10</span>,<span class="number">2</span>) <span class="comment"># 返回以 2 为步长 1 到 9 列表</span></span><br><span class="line">range(<span class="number">0</span>,<span class="number">-10</span>,<span class="number">-1</span>) <span class="comment"># 返回 0 到 -9 列表</span></span><br></pre></td></tr></table></figure>
<h4 id="列表推导式"><a href="#列表推导式" class="headerlink" title="列表推导式"></a>列表推导式</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)] <span class="comment"># 创建一个新 list</span></span><br></pre></td></tr></table></figure>
<h4 id="切片"><a href="#切片" class="headerlink" title="切片"></a>切片</h4><p>list 切片作为右值，会复制数据并返回引用。而对切片的修改会直接作用于原 list 上。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># list[start:stop:step], 用法类似 range，如果意义明确，可省略参数</span></span><br><span class="line"><span class="comment"># 索引可为负，可以超出范围</span></span><br><span class="line">la = lb <span class="comment"># 只能复制引用</span></span><br><span class="line">la = lb[:] <span class="comment"># 复制数据，返回引用给 la</span></span><br><span class="line">lb[::<span class="number">-1</span>] <span class="comment"># lb 逆序列表 copy</span></span><br><span class="line">lb[<span class="number">-2</span>:<span class="number">-1</span>] = [<span class="number">2</span>, <span class="number">4</span>] <span class="comment"># 将 lb 最后两个数赋为 2, 4</span></span><br><span class="line"><span class="keyword">del</span> lb[<span class="number">0</span>:<span class="number">2</span>] <span class="comment"># 删除 lb 第 0、1 号元素</span></span><br></pre></td></tr></table></figure></p>
<h4 id="增加元素"><a href="#增加元素" class="headerlink" title="增加元素"></a>增加元素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list.append(x) <span class="comment"># 追加到末尾</span></span><br><span class="line">list.insert(i, x) <span class="comment"># 插入到 i 处</span></span><br><span class="line">la = lb + lc <span class="comment"># 创建一个新 list，顺序加入 lb、lc 中元素</span></span><br><span class="line">la.extend(lb) <span class="comment"># 在 la 中依次添加 lb 中元素</span></span><br></pre></td></tr></table></figure>
<h4 id="判断元素存在"><a href="#判断元素存在" class="headerlink" title="判断元素存在"></a>判断元素存在</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x <span class="keyword">in</span> list <span class="comment"># 返回 bool 类型，是否存在 x</span></span><br><span class="line">list.count(x) <span class="comment"># 返回 x 出现次数</span></span><br></pre></td></tr></table></figure>
<h4 id="按索引查元素"><a href="#按索引查元素" class="headerlink" title="按索引查元素"></a>按索引查元素</h4><p>索引可为负，范围： [-len, len-1]</p>
<h4 id="按元素查索引"><a href="#按元素查索引" class="headerlink" title="按元素查索引"></a>按元素查索引</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list.index(x) <span class="comment"># 第一次出现 x 位置，如果 x 不存在会报错</span></span><br></pre></td></tr></table></figure>
<h4 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> list[index] <span class="comment"># 删除 index 处元素</span></span><br><span class="line">list.remove(x) <span class="comment"># 删除 x 元素，如果不存在会报错</span></span><br><span class="line">list.pop(index=<span class="number">-1</span>) <span class="comment"># 返回并删除 index 处元素</span></span><br><span class="line"><span class="comment"># 直接用切片复制保留元素到新列表中，也是一种方法</span></span><br></pre></td></tr></table></figure>
<h4 id="反转"><a href="#反转" class="headerlink" title="反转"></a>反转</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">list.reverse()</span><br></pre></td></tr></table></figure>
<h4 id="zip-合并"><a href="#zip-合并" class="headerlink" title="zip 合并"></a>zip 合并</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zip(la,lb,lc) <span class="comment"># “同索引元素”组成元组，构成列表，长度为输入最短列表的长度</span></span><br><span class="line">[a + b <span class="keyword">for</span> a,b <span class="keyword">in</span> zip(la,lb)]</span><br></pre></td></tr></table></figure>
<h3 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h3><p>一个模块是一个源文件，文件名即模块名。模块由 <code>import</code> 语句加载后，便可以访问其中定义的对象。</p>
<h4 id="import-与-from-import"><a href="#import-与-from-import" class="headerlink" title="import 与 from import"></a>import 与 from import</h4><p>当 python 解释器 <code>import</code> 一个模块时，会执行其中的代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> module <span class="comment"># 加载 module，使用其中对象时应该用 module.obj</span></span><br><span class="line"><span class="keyword">from</span> module <span class="keyword">import</span> obj <span class="comment"># 加载 module，只能使用 obj 对象，不用加 module 前缀</span></span><br></pre></td></tr></table></figure></p>
<h4 id="name-属性"><a href="#name-属性" class="headerlink" title="__name__ 属性"></a><code>__name__</code> 属性</h4><p>当 python 解释器加载一个模块时，会设置每个模块的属性 <code>__name__</code>。 只有当前运行模块的该属性被设置为 <code>__main__</code>，所以可用以下语句判断当前模块是否是程序入口<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<h4 id="模块搜索路径"><a href="#模块搜索路径" class="headerlink" title="模块搜索路径"></a>模块搜索路径</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sys.path 列表存储了模块搜索路径</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path <span class="comment"># 可修改该列表以修改模块搜索路径</span></span><br></pre></td></tr></table></figure>
<p>搜索路径初始包括：</p>
<ul>
<li>运行脚本目录</li>
<li>环境变量 PYTHONPATH 中存储的值</li>
<li>Python 模块的安装目录</li>
</ul>
<h4 id="dir"><a href="#dir" class="headerlink" title="dir()"></a>dir()</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dir() <span class="comment"># 返回当前模块定义的对象名列表</span></span><br><span class="line">dir(module) <span class="comment"># 返回 module 定义的对象名列表</span></span><br></pre></td></tr></table></figure>
<h4 id="模块安装"><a href="#模块安装" class="headerlink" title="模块安装"></a>模块安装</h4><p>三种方式：</p>
<p>进入下载安装包目录，运行 setup.py 程序：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 源码安装</span></span><br><span class="line">cd download_dir</span><br><span class="line">python setup.py install <span class="comment"># 运行 setup.py 安装程序</span></span><br><span class="line"><span class="comment"># 用 pip 安装，自动安装依赖包</span></span><br><span class="line">pip install PackageName</span><br><span class="line"><span class="comment"># 用 easy_install 安装，不推荐使用</span></span><br><span class="line">easy_install PackageName</span><br></pre></td></tr></table></figure></p>
<h4 id="win下-Anaconda-安装依赖包"><a href="#win下-Anaconda-安装依赖包" class="headerlink" title="win下 Anaconda 安装依赖包"></a>win下 Anaconda 安装依赖包</h4><p>进入Anaconda安装目录<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd Scripts</span><br><span class="line">pip install PackageName -i https://pypi.tuna.tsinghua.edu.cn/simple/</span><br><span class="line"># -i 后接国内镜像地址url，提升速度</span><br></pre></td></tr></table></figure></p>
<p>更换conda源（清华）：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</span><br><span class="line">conda config --<span class="built_in">set</span> show_channel_urls yes</span><br></pre></td></tr></table></figure></p>
<h3 id="包"><a href="#包" class="headerlink" title="包"></a>包</h3><p>是一个包含 __init__.py 的文件夹，导入模块时需要加上包前缀，类似 Java。</p>
<h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><h4 id="三大作用域"><a href="#三大作用域" class="headerlink" title="三大作用域"></a>三大作用域</h4><p>只有模块（module），类（class）以及函数（<code>def</code>、<code>lambda</code>）才会引入新的作用域，其它的代码块（如if、try、for等，甚至列表推导式也是）不会引入新的作用域</p>
<h4 id="子级作用域与上级"><a href="#子级作用域与上级" class="headerlink" title="子级作用域与上级"></a>子级作用域与上级</h4><p>在子级作用域可访问上级作用域变量。让上级变量指向另一个对象不能使用语句 <code>same_name = obj</code>， 该句被视为在子级作用域定义一个同名变量，并隐藏了上级变量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">()</span>:</span></span><br><span class="line">  print(<span class="string">"read y: %d"</span> % y) <span class="comment"># 读取全局变量</span></span><br><span class="line">  x = <span class="number">1</span>   <span class="comment"># 创建一个局部变量 x</span></span><br><span class="line"></span><br><span class="line">x, y = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">run()</span><br><span class="line">print(<span class="string">"global x: %d"</span> % x)</span><br></pre></td></tr></table></figure>
<h4 id="global-与-nonlocal-语句"><a href="#global-与-nonlocal-语句" class="headerlink" title="global 与 nonlocal 语句"></a>global 与 nonlocal 语句</h4><p>如果想在子级作用域中让上级作用域变量指向其他对象，可以用 <code>global</code> 与 <code>nonlocal</code> 语句。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">x, y = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">outer</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="comment"># nonlocal x 这样声明会报错，python 不能找到非全局的上级变量 x</span></span><br><span class="line">    x, y = <span class="number">1</span>, <span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inner</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">nonlocal</span> x</span><br><span class="line">        x = <span class="number">2</span></span><br><span class="line">        <span class="keyword">global</span> y</span><br><span class="line">        y = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    inner()</span><br><span class="line">    print(<span class="string">"outer:"</span>, x, y)</span><br><span class="line"></span><br><span class="line">outer()</span><br><span class="line">print(<span class="string">"global:"</span>, x, y)</span><br><span class="line"><span class="comment"># 输出：</span></span><br><span class="line"><span class="comment"># outer: 2 1</span></span><br><span class="line"><span class="comment"># global: 0 2</span></span><br></pre></td></tr></table></figure>
<p><code>global</code> 最先出现，用于在局部引用全局变量，随后又加入 <code>nonlocal</code>，使子级作用域引用 <strong>非全局的</strong> 上级变量。</p>
<h4 id="类变量与实例变量"><a href="#类变量与实例变量" class="headerlink" title="类变量与实例变量"></a>类变量与实例变量</h4><p>类变量的定义与访问其中两种方式：</p>
<ul>
<li><code>class_name.class_var</code></li>
<li>类定义内方法定义外 <code>class_var</code></li>
</ul>
<p>实例变量定义与访问有两种方式：</p>
<ul>
<li><code>obj_name.obj_var</code></li>
<li>在有 <code>self</code> 参数的方法定义中 <code>self.obj_var</code></li>
</ul>
<p>用访问实例的方式可以访问类变量，就像 <strong>在子级作用域访问上级变量</strong>，只能访问而不能让其指向另一个对象，而且如果实例变量与类变量同名则访问实例变量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">cls</span>:</span></span><br><span class="line">    v1 = <span class="number">0</span>  <span class="comment"># 定义类变量</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.v1 = <span class="number">1</span>   <span class="comment"># 定义实例变量，隐藏同名类变量</span></span><br><span class="line"></span><br><span class="line">cls.v2 = <span class="number">0</span>  <span class="comment"># 定义类变量</span></span><br><span class="line">obj = cls()</span><br><span class="line"><span class="keyword">print</span> cls.v1, cls.v2  <span class="comment"># 访问类变量</span></span><br><span class="line"><span class="keyword">print</span> obj.v1, obj.v2  <span class="comment"># 分别访问实例变量 v1 与类变量 v2</span></span><br></pre></td></tr></table></figure>
<h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><h4 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h4><p>类似 C 语言的格式化字符串，用 % 号连接模板字符串（Template）与匹配元组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'%s is a string. %d is a int.'</span> % (<span class="string">"Hello World"</span>, <span class="number">0</span>) <span class="comment"># 该表达式返回一个字符串</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可将元组替换成字典，模板对应加入 (key)</span></span><br><span class="line"><span class="string">"I'm %(name)s, and I love %(num)g."</span> % &#123;<span class="string">"num"</span>:math.pi, <span class="string">"name"</span>:<span class="string">"Mike"</span>&#125;</span><br></pre></td></tr></table></figure>
<h4 id="原生字符串（常量）"><a href="#原生字符串（常量）" class="headerlink" title="原生字符串（常量）"></a>原生字符串（常量）</h4><p>在字符串字面量前加 r ，会使之成为原生字符串字面量，不会对字符进行转义。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r"\n"</span> == <span class="string">"\\n"</span> <span class="comment"># 返回 True</span></span><br></pre></td></tr></table></figure>
<h4 id="加操作"><a href="#加操作" class="headerlink" title="加操作"></a>加操作</h4><p><strong>字符串只允许与字符串进行加操作</strong></p>
<h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><h4 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h4><p>函数形参（函数定义参数）复制了实参（传入函数的变量）的引用，类似 Java，对形参引用对象的修改实际上在修改实参引用对象，但让形参指向其他对象不会对实参有影响。</p>
<h4 id="缺省与变长"><a href="#缺省与变长" class="headerlink" title="缺省与变长"></a>缺省与变长</h4><p>函数参数的定义顺序与调用顺序应该遵循：关键字参数–&gt;缺省参数–&gt;变长参数–&gt;关键字参变长数</p>
<h5 id="关键字参数"><a href="#关键字参数" class="headerlink" title="关键字参数"></a>关键字参数</h5><p>最基本的一类参数，调用时可指明形参名（关键字）。与其他参数不同，必需赋值。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> a, b</span><br><span class="line">fun(<span class="number">1</span>, <span class="number">2</span>) <span class="comment"># 一般调用方法</span></span><br><span class="line">fun(b=<span class="number">1</span>, a=<span class="number">2</span>)  <span class="comment"># 指明形参名可乱序</span></span><br><span class="line">fun(<span class="number">1</span>, b=<span class="number">2</span>) <span class="comment"># 可行</span></span><br><span class="line">fun(<span class="number">1</span>, a=<span class="number">2</span>) <span class="comment"># 这样调用出错</span></span><br><span class="line">fun(a=<span class="number">1</span>, <span class="number">2</span>) <span class="comment"># 同样出错</span></span><br></pre></td></tr></table></figure></p>
<h5 id="缺省参数"><a href="#缺省参数" class="headerlink" title="缺省参数"></a>缺省参数</h5><p>缺省参数有缺省值。除了顺序在关键字参数后以及有缺省值外，与关键字参数基本相同。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a, b=<span class="number">2</span>)</span>:</span>  <span class="comment"># b 为缺省参数</span></span><br><span class="line">    <span class="keyword">print</span> a, b</span><br><span class="line">fun(<span class="number">1</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<h5 id="变长参数"><a href="#变长参数" class="headerlink" title="变长参数"></a>变长参数</h5><p>参数个数不定，形参最终得到元组，调用时可不传，一个个传递或传一个元组。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a, *b)</span>:</span> <span class="comment"># b 为变长参数</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> b:</span><br><span class="line">        <span class="keyword">print</span> a + i</span><br><span class="line">fun(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">fun(<span class="number">1</span>, *(<span class="number">2</span>, <span class="number">3</span>)) <span class="comment"># 用元组传递变长参数，加星号，称作解包</span></span><br><span class="line">fun(<span class="number">1</span>)  <span class="comment"># 不传或解包空元组都可行</span></span><br></pre></td></tr></table></figure></p>
<h5 id="关键字变长参数"><a href="#关键字变长参数" class="headerlink" title="关键字变长参数"></a>关键字变长参数</h5><p>参数个数不定，而且必须指明关键字。形参最终得到字典，与变长参数类似，调用时可不传，一个个传递或传一个字典。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> kwargs.items():    </span><br><span class="line">        <span class="keyword">print</span> <span class="string">"get "</span> + k + <span class="string">"="</span> + str(v)</span><br><span class="line">fun(a=<span class="number">1</span>, s=<span class="string">"hi"</span>)</span><br><span class="line">fun(**&#123;<span class="string">"a"</span>: <span class="number">1</span>, <span class="string">"s"</span>: <span class="string">"hi"</span>&#125;)  <span class="comment"># 字典解包，注意关键字必须为字符串</span></span><br></pre></td></tr></table></figure></p>
<h5 id="参数顺序"><a href="#参数顺序" class="headerlink" title="参数顺序"></a>参数顺序</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a, b=<span class="number">1</span>, *c, **d)</span>:</span> <span class="comment"># 函数定义时形参须根据类型按序定义</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">fun(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, d1=<span class="number">4</span>) <span class="comment"># 函数调用时也根据类型按序传入</span></span><br></pre></td></tr></table></figure>
<h3 id="常识"><a href="#常识" class="headerlink" title="常识"></a>常识</h3><h4 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h4><ul>
<li>元素不能改变</li>
</ul>
<h4 id="False"><a href="#False" class="headerlink" title="False"></a>False</h4><p>判断语句中None,False,空字符串””,0,空列表[],空字典{},空元组()都相当于False</p>
<h4 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo pip3 install virtualenv</span><br><span class="line"><span class="comment"># 创建虚拟环境，python3，无已安装包</span></span><br><span class="line">virtualenv -p python3 --no-site-packages venv</span><br><span class="line"><span class="built_in">source</span> venv/bin/activate <span class="comment"># 激活</span></span><br><span class="line">pip freeze &gt; requirement <span class="comment"># pip freeze</span></span><br><span class="line">deactivate <span class="comment"># 退出虚拟环境</span></span><br></pre></td></tr></table></figure>
<h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="当前目录"><a href="#当前目录" class="headerlink" title="当前目录"></a>当前目录</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.getcwd()</span><br></pre></td></tr></table></figure>
<h4 id="简单文件读写"><a href="#简单文件读写" class="headerlink" title="简单文件读写"></a>简单文件读写</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">col = []</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'file_path.csv'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> df:</span><br><span class="line">  <span class="keyword">for</span> line <span class="keyword">in</span> df:</span><br><span class="line">      tmp = line.strip().split(<span class="string">','</span>)</span><br><span class="line">      col.append(int(tmp[<span class="number">3</span>])) <span class="comment"># 读取第4列</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'out_path'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> df: <span class="comment"># 'a' 追加</span></span><br><span class="line">  <span class="keyword">for</span> val <span class="keyword">in</span> col:</span><br><span class="line">    df.write(<span class="string">"%d\n"</span> % val)</span><br></pre></td></tr></table></figure>
<h4 id="在控制台运行源文件"><a href="#在控制台运行源文件" class="headerlink" title="在控制台运行源文件"></a>在控制台运行源文件</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">execfile(<span class="string">'python_code.py'</span>)</span><br></pre></td></tr></table></figure>
<h3 id="错误及解决办法"><a href="#错误及解决办法" class="headerlink" title="错误及解决办法"></a>错误及解决办法</h3><h4 id="pip安装出现SOCKS支持问题"><a href="#pip安装出现SOCKS支持问题" class="headerlink" title="pip安装出现SOCKS支持问题"></a>pip安装出现SOCKS支持问题</h4><p>报错<code>Missing dependencies for SOCKS support</code>。在Ubuntu下，用<code>unset all_proxy &amp;&amp; unset ALL_PROXY</code>命令解除代理设置。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/06/03/C-Cpp-cheatSheet/" itemprop="url">
                  C/Cpp 杂记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-06-03T10:47:21+08:00" content="2016-06-03">
              2016-06-03
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/C-C/" itemprop="url" rel="index">
                    <span itemprop="name">C/C++</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h3><h4 id="简单文件读写"><a href="#简单文件读写" class="headerlink" title="简单文件读写"></a>简单文件读写</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line">ifstream in;</span><br><span class="line">in.open(<span class="string">"file_path"</span>);</span><br><span class="line"><span class="keyword">int</span> k;</span><br><span class="line"><span class="keyword">while</span>(in &gt;&gt; k)  <span class="comment">// 读取 int 型数据</span></span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; k &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">in.close();</span><br><span class="line"></span><br><span class="line">ofstream out;</span><br><span class="line">out.open(<span class="string">"out_path"</span>, ios::app); <span class="comment">// app模式追加，默认覆写</span></span><br><span class="line">out &lt;&lt; ‘hello world’ &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">out.close();</span><br></pre></td></tr></table></figure>
<h3 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h3><h4 id="循环计数器与-运算符"><a href="#循环计数器与-运算符" class="headerlink" title="循环计数器与 ++ 运算符"></a>循环计数器与 ++ 运算符</h4><p>考虑 while 和 do 计数循环：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">while</span>(++i &lt; <span class="number">1</span>)</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"while: "</span> &lt;&lt; i &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// i 不会被打印</span></span><br><span class="line"></span><br><span class="line">i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">do</span>&#123;</span><br><span class="line">  <span class="built_in">cout</span> &lt;&lt; <span class="string">"do: "</span> &lt;&lt; i &lt;&lt; <span class="built_in">endl</span>;  <span class="comment">// i 被打印2次</span></span><br><span class="line">&#125;<span class="keyword">while</span>(i++ &lt; <span class="number">1</span>);</span><br></pre></td></tr></table></figure></p>
<p>这里计数器 i 不能正常工作（打印一次），应该将计数器更新放在循环体避免失误，使用标准的 for 循环最好。</p>
<h4 id="结构体声明"><a href="#结构体声明" class="headerlink" title="结构体声明"></a>结构体声明</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">struct_label</span>&#123;</span></span><br><span class="line"></span><br><span class="line">&#125;; <span class="comment">// 结构标记声明</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">struct_label</span> <span class="title">var_name</span>;</span> <span class="comment">// 结构变量声明</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">struct_label</span>&#123;</span></span><br><span class="line"></span><br><span class="line">&#125; var_name; <span class="comment">// 结构标记与变量同时声明</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line"></span><br><span class="line">&#125; struct_type, *p_struct_type;  <span class="comment">// 结构typedef名声明</span></span><br><span class="line">struct_type var_name; <span class="comment">// 结构变量声明</span></span><br><span class="line">p_struct_type var_name; <span class="comment">// 结构指针变量声明</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">struct_label</span>&#123;</span></span><br><span class="line"></span><br><span class="line">&#125; struct_type, *p_struct_type;  <span class="comment">// 结构标记与typedef名同时声明</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">  ElemType data;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">node</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125; Node, *PNode; <span class="comment">// 链表结点结构体典型声明</span></span><br></pre></td></tr></table></figure>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Blunt" />
          <p class="site-author-name" itemprop="name">Blunt</p>
          <p class="site-description motion-element" itemprop="description">email：summer15y@163.com</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">72</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">37</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Blunt</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


  

  

  


</body>
</html>
